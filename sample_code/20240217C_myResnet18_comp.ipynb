{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4b3af0-8796-4f91-a3b8-a189ed4b5b47",
   "metadata": {},
   "source": [
    "# 自前のネットワークを組んで学習させてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7703dc5b-ee9d-4aaa-add2-f96d5029ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41647b1b-afa7-4fd6-ae50-20a1694f1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = r'./dataset_cur_train.csv'\n",
    "test_fn = r'./dataset_cur_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fd0446-9e09-443b-9a85-463eec4bdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir_path_recursive = './myResnet18C/'\n",
    "os.makedirs(new_dir_path_recursive, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5294d05-3e0d-461d-83fc-16ebda6d1449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "redpoint_-3            int64\n",
       "redpoint_-2            int64\n",
       "redpoint_-1            int64\n",
       "redpoint_0             int64\n",
       "redpoint_1             int64\n",
       "redpoint_2             int64\n",
       "redpoint_3             int64\n",
       "pred                   int64\n",
       "ends                   int64\n",
       "red                  float64\n",
       "yellow               float64\n",
       "red_diff             float32\n",
       "remain_ends          float32\n",
       "last_stone_is_red    float32\n",
       "red_postion          float32\n",
       "filepath              object\n",
       "page                   int64\n",
       "T                     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "      <th>pred</th>\n",
       "      <th>ends</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "      <th>page</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...</td>\n",
       "      <td>462</td>\n",
       "      <td>ECC2023_ResultsBook_Women_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...</td>\n",
       "      <td>318</td>\n",
       "      <td>CWC2018-19_Leg3_ResultsBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png</td>\n",
       "      <td>600</td>\n",
       "      <td>WWCC2022_ResultsBook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "2            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  pred  ends  red  yellow  red_diff  remain_ends  \\\n",
       "0           0    -3     4  0.0     3.0      -3.0          5.0   \n",
       "1           0     1     7  1.0     0.0       1.0          2.0   \n",
       "2           0     1     4  1.0     0.0       1.0          5.0   \n",
       "\n",
       "   last_stone_is_red  red_postion  \\\n",
       "0                0.0         -3.0   \n",
       "1                1.0          3.0   \n",
       "2                1.0          0.0   \n",
       "\n",
       "                                            filepath  page  \\\n",
       "0  ./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...   462   \n",
       "1  ./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...   318   \n",
       "2   ./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png   600   \n",
       "\n",
       "                                      T  \n",
       "0  ECC2023_ResultsBook_Women_A-Division  \n",
       "1           CWC2018-19_Leg3_ResultsBook  \n",
       "2                  WWCC2022_ResultsBook  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_fn,index_col=0)\n",
    "df_train['red_diff'] = df_train['red_diff'].astype(np.float32)\n",
    "df_train['remain_ends'] = df_train['remain_ends'].astype(np.float32)\n",
    "df_train['last_stone_is_red'] = df_train['last_stone_is_red'].astype(np.float32)\n",
    "df_train['red_postion'] = df_train['red_postion'].astype(np.float32)\n",
    "display(df_train.dtypes)\n",
    "display(df_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416d239-816d-4246-98c9-68aa35baafb0",
   "metadata": {},
   "source": [
    "## red_diff&red_point が目的、fn,remain_ends,last_stone_is_red,red_postion が説明変数\n",
    "説明変数を標準化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa9751-11cd-40b2-a6c4-1ae948374df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba7ce319-2e82-424f-94ff-2a6171635c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3675206 , -1.0015383 , -1.2659631 ],\n",
       "       [-0.78656346,  0.99846405,  1.2369138 ],\n",
       "       [ 0.3675206 ,  0.99846405, -0.0145247 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([4.04464345, 0.50076856, 0.03481922])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([6.757213  , 0.24999941, 5.74676597])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "      <th>pred</th>\n",
       "      <th>ends</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "      <th>page</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>-1.001538</td>\n",
       "      <td>-1.265963</td>\n",
       "      <td>./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...</td>\n",
       "      <td>462</td>\n",
       "      <td>ECC2023_ResultsBook_Women_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.786563</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>1.236914</td>\n",
       "      <td>./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...</td>\n",
       "      <td>318</td>\n",
       "      <td>CWC2018-19_Leg3_ResultsBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>-0.014525</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png</td>\n",
       "      <td>600</td>\n",
       "      <td>WWCC2022_ResultsBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.171258</td>\n",
       "      <td>-1.001538</td>\n",
       "      <td>1.654060</td>\n",
       "      <td>./dataset_o\\ECC2022_ResultsBook_Men_A-Division...</td>\n",
       "      <td>23</td>\n",
       "      <td>ECC2022_ResultsBook_Men_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.171258</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>-0.848817</td>\n",
       "      <td>./dataset_o\\WWCC2018_ResultsBook\\geme722end8.png</td>\n",
       "      <td>722</td>\n",
       "      <td>WWCC2018_ResultsBook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "2            0            0            0           0           1           0   \n",
       "3            0            1            0           0           0           0   \n",
       "4            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  pred  ends  red  yellow  red_diff  remain_ends  \\\n",
       "0           0    -3     4  0.0     3.0      -3.0     0.367521   \n",
       "1           0     1     7  1.0     0.0       1.0    -0.786563   \n",
       "2           0     1     4  1.0     0.0       1.0     0.367521   \n",
       "3           0    -2     8  0.0     2.0      -2.0    -1.171258   \n",
       "4           0     1     8  1.0     0.0       1.0    -1.171258   \n",
       "\n",
       "   last_stone_is_red  red_postion  \\\n",
       "0          -1.001538    -1.265963   \n",
       "1           0.998464     1.236914   \n",
       "2           0.998464    -0.014525   \n",
       "3          -1.001538     1.654060   \n",
       "4           0.998464    -0.848817   \n",
       "\n",
       "                                            filepath  page  \\\n",
       "0  ./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...   462   \n",
       "1  ./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...   318   \n",
       "2   ./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png   600   \n",
       "3  ./dataset_o\\ECC2022_ResultsBook_Men_A-Division...    23   \n",
       "4   ./dataset_o\\WWCC2018_ResultsBook\\geme722end8.png   722   \n",
       "\n",
       "                                      T  \n",
       "0  ECC2023_ResultsBook_Women_A-Division  \n",
       "1           CWC2018-19_Leg3_ResultsBook  \n",
       "2                  WWCC2022_ResultsBook  \n",
       "3    ECC2022_ResultsBook_Men_A-Division  \n",
       "4                  WWCC2018_ResultsBook  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化\n",
    "stdsc = StandardScaler()\n",
    "##学習時の標準化したパラメータは、評価、本番時におなじ重みで標準化する処理が必要\n",
    "x_train_df  = df_train[['remain_ends','last_stone_is_red','red_postion']].copy()\n",
    "x_train_std = stdsc.fit_transform(x_train_df)\n",
    "display( x_train_std[:3] )\n",
    "display(stdsc.n_features_in_, stdsc.mean_ , stdsc.var_) \n",
    "pickle.dump(stdsc, open(new_dir_path_recursive+\"stdsc_02240209.pkl\", \"wb\"))\n",
    "\n",
    "df_train[['remain_ends','last_stone_is_red','red_postion']] = x_train_std\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a26fa-baaf-42e8-9364-5c7b6e3c9a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "232f4a74-d1e7-4304-a0f7-933485b4a9ba",
   "metadata": {},
   "source": [
    "### RESNET18\n",
    "https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html  \n",
    "crop = 224\n",
    "mean=[0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc251581-3052-406f-94bf-c781ea7943a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    ##torch.backends.cudnn.deterministic = True\n",
    "    ##torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d98501e-1d3d-4b23-bb83-646cf5a3f981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 540]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 画像変換の定義\n",
    "w,h = Image.open(df_train['filepath'].values[0]).size\n",
    "## 正方形にするための差分\n",
    "pad = (h-w)/2\n",
    "display([w,h],pad)\n",
    "target_size = 224\n",
    "## train用\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# valid/test用\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22f5154d-84a6-42eb-b638-dbab73d94516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3     841\n",
       " -2    2032\n",
       " -1    3619\n",
       "  0    1807\n",
       "  1    3720\n",
       "  2    2115\n",
       "  3     829\n",
       " dtype: int64,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_data = pd.get_dummies(df_train['pred'])\n",
    "class_data.sum() , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7879ed0-c0bc-4169-9ded-dc208041cdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['redpoint_-3',\n",
       " 'redpoint_-2',\n",
       " 'redpoint_-1',\n",
       " 'redpoint_0',\n",
       " 'redpoint_1',\n",
       " 'redpoint_2',\n",
       " 'redpoint_3']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  \n",
       "0           0  \n",
       "1           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_cols = list(filter( lambda s:s.startswith('redpoint_'),  df_train.columns))\n",
    "display(labels_cols , df_train[labels_cols][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed388034-7646-46b5-aefb-09880fa1571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_cols = ['remain_ends','last_stone_is_red','red_postion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f773c-6504-40e9-a103-bd8b100ab1a2",
   "metadata": {},
   "source": [
    "# 自前のデータセット定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f04521e7-c7bd-4a5d-9a0c-71a00502dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgValueDataset(Dataset):\n",
    "    def __init__(self, df, classcol , fncol ,extendcol, transform):\n",
    "        \n",
    "        self.img_pathlist = df[fncol].values\n",
    "        \n",
    "        class_data = df[classcol].values\n",
    "        self.label_list  = class_data.astype(float)\n",
    "        \n",
    "        self.val_list  = df[extendcol].astype(np.float16).values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len( self.img_pathlist )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 画像をPILとして読み込む\n",
    "        #print(index,self.img_pathlist[index])\n",
    "        image = Image.open(self.img_pathlist[index])\n",
    "        \n",
    "        label = self.label_list[index]\n",
    "\n",
    "        extend = self.val_list[index]                         \n",
    "        if self.transform is not None:\n",
    "            ##print('use transform')\n",
    "            image = self.transform(image)\n",
    "        ## 次元を足してやってっそこに追加データを結合\n",
    "        extend_tensor = np.full((224,224),255)\n",
    "        extend_tensor[1][0] = extend[0]\n",
    "        extend_tensor[1][1] = extend[1]\n",
    "        extend_tensor[1][2] = extend[2]\n",
    "        #print(extend_tensor)\n",
    "        extend_tensor = torch.Tensor(extend_tensor)\n",
    "        extend_tensor = extend_tensor.unsqueeze(0)\n",
    "        out = torch.cat([image, extend_tensor], dim=0)\n",
    "                             \n",
    "        return out, label \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d21f2ff-a686-4a02-9e5a-8dae8ed9f844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "      <th>pred</th>\n",
       "      <th>ends</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "      <th>page</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>-1.001538</td>\n",
       "      <td>-1.265963</td>\n",
       "      <td>./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...</td>\n",
       "      <td>462</td>\n",
       "      <td>ECC2023_ResultsBook_Women_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.786563</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>1.236914</td>\n",
       "      <td>./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...</td>\n",
       "      <td>318</td>\n",
       "      <td>CWC2018-19_Leg3_ResultsBook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  pred  ends  red  yellow  red_diff  remain_ends  \\\n",
       "0           0    -3     4  0.0     3.0      -3.0     0.367521   \n",
       "1           0     1     7  1.0     0.0       1.0    -0.786563   \n",
       "\n",
       "   last_stone_is_red  red_postion  \\\n",
       "0          -1.001538    -1.265963   \n",
       "1           0.998464     1.236914   \n",
       "\n",
       "                                            filepath  page  \\\n",
       "0  ./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...   462   \n",
       "1  ./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...   318   \n",
       "\n",
       "                                      T  \n",
       "0  ECC2023_ResultsBook_Women_A-Division  \n",
       "1           CWC2018-19_Leg3_ResultsBook  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1a795a1-a4b0-4f93-bb8d-9544cce15f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['redpoint_-3',\n",
       "  'redpoint_-2',\n",
       "  'redpoint_-1',\n",
       "  'redpoint_0',\n",
       "  'redpoint_1',\n",
       "  'redpoint_2',\n",
       "  'redpoint_3'],\n",
       " ['remain_ends', 'last_stone_is_red', 'red_postion'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_train, test_size=0.2, stratify=df_train['pred'])\n",
    "labels_cols,extend_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17254037-db32-49a6-bd17-e1c2101da310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11970, 2993)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ImgValueDataset( train_df ,classcol=labels_cols , fncol='filepath',extendcol = extend_cols , transform=transform_train)\n",
    "test_dataset = ImgValueDataset( test_df ,classcol=labels_cols , fncol='filepath' ,extendcol = extend_cols ,transform=transform_test)\n",
    "len(train_df) , len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a9aa0e0-f19c-4983-846a-4fb6955f5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f12baa4-eaf9-43e9-aed0-30be6dabc706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2993"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b80edabd-3b50-49e8-aec9-88cb63cfa1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 224, 224]),\n",
       " tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels  = next(iter(train_loader))\n",
    "inputs.shape , labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "409e018e-0b4b-4b1a-9364-347f19600945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,  -1.,   0., 255., 255.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#分割テスト\n",
    "one_sampe = inputs[2,]\n",
    "p = torchvision.transforms.functional.to_pil_image(one_sampe[0:2])\n",
    "fig,ax=plt.subplots(1,1,figsize=(2,2))\n",
    "plt.imshow(p) \n",
    "one_sampe[3,1,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f0cda-b0ce-4e75-a54d-7cbc9ac14da9",
   "metadata": {},
   "source": [
    "# ネットを組む  \n",
    "https://qiita.com/poorko/items/c151ff4a827f114fe954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5020444e-2c32-49c1-ad66-ef1f25ec37c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./myResnet18C/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import glob\n",
    "new_dir_path_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e13e5752-aa83-4961-bc43-206295071cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./myResnet18C\\resnet18-f37072fd.pth\n",
      "<class 'torchvision.models.resnet.ResNet'> tensor([-0.0026,  0.0030,  0.0007, -0.0269,  0.0064,  0.0133, -0.0112,  0.0206,\n",
      "        -0.0036, -0.0123], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=False)\n",
    "g = glob.glob(new_dir_path_recursive + 'resnet18*.pth')\n",
    "fn = g[0]\n",
    "print(fn)\n",
    "model_ft.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc.bias[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e80e3677-aec5-4ee1-89c8-3477082cf25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.resnet.ResNet'> tensor([-0.0026,  0.0030,  0.0007, -0.0269,  0.0064,  0.0133, -0.0112,  0.0206,\n",
      "        -0.0036, -0.0123], grad_fn=<SliceBackward0>)\n",
      "すべてのネットの重みをロック [ True]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.resnet import ResNet,Bottleneck,BasicBlock\n",
    "net = ResNet(block=BasicBlock,layers=[2, 2, 2, 2],num_classes=1000)\n",
    "net.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc.bias[:10] )\n",
    "\n",
    "for i, param in enumerate(net.parameters()):\n",
    "        param.requires_grad = True #False\n",
    "x = [ param.requires_grad for param in net.parameters()]\n",
    "print('すべてのネットの重みをロック',np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9071b23-251b-41aa-94c9-4af1a7eeda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "##派生がうまくいって重みが入るかチェック\n",
    "class _myResnet18(models.resnet.ResNet):\n",
    "    def __init__(self, block,layers,num_classes):\n",
    "        super().__init__(block,layers,num_classes)\n",
    "        print(_myResnet18)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0683e0d-6e78-4268-aacd-6418819cab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__._myResnet18'>\n",
      "<class 'torchvision.models.resnet.ResNet'> Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.resnet import ResNet,Bottleneck,BasicBlock\n",
    "net = _myResnet18(block=BasicBlock,layers=[2, 2, 2, 2],num_classes=1000)\n",
    "net.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa77fd16-ed06-4277-a45b-28af18165bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNモデルの定義\n",
    "class myResnet18(models.resnet.ResNet):\n",
    "    def __init__(self, block,layers,num_classes):\n",
    "        super().__init__(block,layers,num_classes)\n",
    "        pass\n",
    "class myResnet18(models.resnet.ResNet):\n",
    "    def forward(self, xpacked:torch.Tensor) -> torch.Tensor:\n",
    "        input = xpacked\n",
    "        #print('input:',input.shape)\n",
    "        x = input[:,:3]　## 画像部分\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        ###########################################\n",
    "        params = input[:,3,1,0:3]　## 数値部分\n",
    "        output = torch.cat([x,params],1)\n",
    "        ###########################################\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "47ebb57a-9899-443e-b0d4-717c55a04878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.resnet.ResNet'> tensor([-0.0026,  0.0030,  0.0007, -0.0269,  0.0064,  0.0133, -0.0112,  0.0206,\n",
      "        -0.0036, -0.0123], grad_fn=<SliceBackward0>)\n",
      "すべてのネットの重みをロック [False]\n",
      "最後の一つを切り替えたので混在するのが正しい: [False  True]\n"
     ]
    }
   ],
   "source": [
    "net = myResnet18(block=BasicBlock,layers=[2, 2, 2, 2],num_classes=1000)\n",
    "net.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc.bias[:10] )\n",
    "\n",
    "## 重みロック\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "x = [ param.requires_grad for param in net.parameters()]\n",
    "print('すべてのネットの重みをロック',np.unique(x))\n",
    "## 最終を置き換える\n",
    "net.fc = nn.Sequential(\n",
    "    nn.Linear(512+3, 1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(1024, len(labels_cols)),\n",
    ")\n",
    "##display(net)\n",
    "x = [ param.requires_grad for param in net.parameters()]\n",
    "print('最後の一つを切り替えたので混在するのが正しい:',np.unique(x)) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "519985fb-750b-4cc4-8fb8-0e5392d8cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 関数化して\n",
    "def createMyNet():\n",
    "    net = myResnet18(block=BasicBlock,layers=[2, 2, 2, 2],num_classes=1000)\n",
    "    net.load_state_dict(torch.load(g[0]))\n",
    "    \n",
    "    ## 重みロック\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "    ## 最終段をlabels_colsにする\n",
    "    num_class = len(labels_cols)\n",
    "    ## 最終を置き換える\n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs+3, 1024),\n",
    "##        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(1024, len(labels_cols)),\n",
    "    )\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b142fe7-2cbb-48de-8145-194d58d8eb3c",
   "metadata": {},
   "source": [
    "https://qiita.com/ku_a_i/items/ba33c9ce3449da23b503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7faeb50a-94cd-430b-ab51-b974472b2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"earlystoppingクラス\"\"\"\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):\n",
    "        \"\"\"引数：最小値の非更新数カウンタ、表示設定、モデル格納path\"\"\"\n",
    "\n",
    "        self.patience = patience    #設定ストップカウンタ\n",
    "        self.verbose = verbose      #表示の有無\n",
    "        self.counter = 0            #現在のカウンタ値\n",
    "        self.best_score = None      #ベストスコア\n",
    "        self.early_stop = False     #ストップフラグ\n",
    "        self.val_loss_min = np.Inf   #前回のベストスコア記憶用\n",
    "        self.path = path             #ベストモデル格納path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        特殊(call)メソッド\n",
    "        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n",
    "        \"\"\"\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  #1Epoch目の処理\n",
    "            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する\n",
    "            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する\n",
    "        elif score < self.best_score:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1   #ストップカウンタを+1\n",
    "            if self.verbose:  #表示を有効にした場合は経過を表示\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する \n",
    "            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "        else:  #ベストスコアを更新した場合\n",
    "            self.best_score = score  #ベストスコアを上書き\n",
    "            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示\n",
    "            self.counter = 0  #ストップカウンタリセット\n",
    "\n",
    "    def checkpoint(self, val_loss, model):\n",
    "        '''ベストスコア更新時に実行されるチェックポイント関数'''\n",
    "        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  #ベストモデルを指定したpathに保存\n",
    "        self.val_loss_min = val_loss  #その時のlossを記録する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55720b18-dcac-420f-a31b-49194d6045fa",
   "metadata": {},
   "source": [
    "## 訓練（ネットワークが通るか確認）  \n",
    "https://atmarkit.itmedia.co.jp/ait/articles/2006/12/news021.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2617a006-93d0-421c-aa50-7a870273142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(values1, values2, rng, label1, label2):\n",
    "    plt.plot(range(rng), values1, label=label1)\n",
    "    plt.plot(range(rng), values2, label=label2)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be6637f1-bd47-4c9e-9a0b-5b9478dd7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataloader, criterion, optimizer,device):\n",
    "    net.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #print('入力:',inputs.shape , labels.shape,labels.dtype)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        #print('評価:',outputs.shape , labels.shape,labels.dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, ons_labels = torch.max(labels, 1)\n",
    "        total_correct += (predicted == ons_labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate(net, dataloader, criterion,device):\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, ons_labels = torch.max(labels, 1)\n",
    "            total_correct += (predicted == ons_labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_accuracy = total_correct / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, avg_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "38cb4493-aa41-480b-9dfa-b8a8990ef21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train_and_validate(net, trainset, criterion, optimizer,scheduler, epochs,device):\n",
    "    best_accuracy = 0.0\n",
    "    trainloader, validloader = trainset\n",
    "    curEarlyStopping = EarlyStopping(patience=20, verbose=True,path=new_dir_path_recursive+'checkpoint_model.pth')\n",
    "\n",
    "    history = {}\n",
    "    history['train_loss_values'] = []\n",
    "    history['train_accuracy_values'] = []\n",
    "    history['valid_loss_values'] = []\n",
    "    history['valid_accuracy_values'] = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        current_time = datetime.now()\n",
    "        formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f'epoch: {epoch:3} <{formatted_time}>')\n",
    "\n",
    "        t_loss, t_accu = train(net, trainloader, criterion, optimizer,device)\n",
    "        v_loss, v_accu = validate(net, validloader, criterion,device)\n",
    "\n",
    "        print(f'train_loss: {t_loss:.6f}, train_accuracy: {t_accu:3.4%},',\n",
    "              f'valid_loss: {v_loss:.6f}, valid_accuracy: {v_accu:3.4%}')\n",
    "\n",
    "        history['train_loss_values'].append(t_loss)\n",
    "        history['train_accuracy_values'].append(t_accu)\n",
    "        history['valid_loss_values'].append(v_loss)\n",
    "        history['valid_accuracy_values'].append(v_accu)\n",
    "        pd.DataFrame(history).to_csv(new_dir_path_recursive+'mynet_spec.csv')\n",
    "        if best_accuracy < v_accu:\n",
    "            best_accuracy = v_accu\n",
    "            model_scripted = torch.jit.script(net)\n",
    "            model_scripted.save(new_dir_path_recursive+f'model_scripted_{epoch}.smodel.pth')\n",
    "        # 学習率の動的変更\n",
    "        scheduler.step(v_loss)\n",
    "        #★毎エポックearlystoppingの判定をさせる★\n",
    "        curEarlyStopping( v_loss , net) #callメソッド呼び出し\n",
    "        if curEarlyStopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "            print(\"Early Stopping!\")\n",
    "            return history\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21bf239b-71a8-49e0-8aa4-d00309da60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   1 <2024-02-17 16:55:51>\n",
      "train_loss: 0.134148, train_accuracy: 25.9482%, valid_loss: 0.062879, valid_accuracy: 30.5045%\n",
      "Validation loss decreased (inf --> 0.062879).  Saving model ...\n",
      "epoch:   2 <2024-02-17 16:58:41>\n",
      "train_loss: 0.552815, train_accuracy: 24.9373%, valid_loss: 0.065191, valid_accuracy: 25.7267%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:   3 <2024-02-17 17:01:40>\n",
      "train_loss: 0.058485, train_accuracy: 32.1721%, valid_loss: 0.058148, valid_accuracy: 29.8029%\n",
      "Validation loss decreased (0.062879 --> 0.058148).  Saving model ...\n",
      "epoch:   4 <2024-02-17 17:04:43>\n",
      "train_loss: 0.057562, train_accuracy: 32.3559%, valid_loss: 0.067548, valid_accuracy: 26.8293%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:   5 <2024-02-17 17:07:43>\n",
      "train_loss: 0.062471, train_accuracy: 31.2448%, valid_loss: 0.051249, valid_accuracy: 37.4875%\n",
      "Validation loss decreased (0.058148 --> 0.051249).  Saving model ...\n",
      "epoch:   6 <2024-02-17 17:10:46>\n",
      "train_loss: 0.073281, train_accuracy: 28.5129%, valid_loss: 0.108683, valid_accuracy: 35.3826%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:   7 <2024-02-17 17:13:49>\n",
      "train_loss: 1.427793, train_accuracy: 25.9566%, valid_loss: 0.074513, valid_accuracy: 33.5783%\n",
      "EarlyStopping counter: 2 out of 20\n",
      "epoch:   8 <2024-02-17 17:16:53>\n",
      "train_loss: 0.068536, train_accuracy: 31.9967%, valid_loss: 0.066948, valid_accuracy: 31.0725%\n",
      "EarlyStopping counter: 3 out of 20\n",
      "epoch:   9 <2024-02-17 17:19:55>\n",
      "train_loss: 0.061419, train_accuracy: 33.0493%, valid_loss: 0.055162, valid_accuracy: 35.8837%\n",
      "EarlyStopping counter: 4 out of 20\n",
      "epoch:  10 <2024-02-17 17:22:57>\n",
      "train_loss: 0.060823, train_accuracy: 32.7235%, valid_loss: 0.055422, valid_accuracy: 35.6833%\n",
      "EarlyStopping counter: 5 out of 20\n",
      "epoch:  11 <2024-02-17 17:26:01>\n",
      "train_loss: 0.063398, train_accuracy: 32.2723%, valid_loss: 0.062885, valid_accuracy: 30.8052%\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-03.\n",
      "EarlyStopping counter: 6 out of 20\n",
      "epoch:  12 <2024-02-17 17:29:03>\n",
      "train_loss: 0.047015, train_accuracy: 40.2840%, valid_loss: 0.045495, valid_accuracy: 40.6281%\n",
      "Validation loss decreased (0.051249 --> 0.045495).  Saving model ...\n",
      "epoch:  13 <2024-02-17 17:32:06>\n",
      "train_loss: 0.045505, train_accuracy: 41.2197%, valid_loss: 0.046034, valid_accuracy: 41.5971%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:  14 <2024-02-17 17:35:09>\n",
      "train_loss: 0.045632, train_accuracy: 41.5706%, valid_loss: 0.045975, valid_accuracy: 42.2653%\n",
      "EarlyStopping counter: 2 out of 20\n",
      "epoch:  15 <2024-02-17 17:38:12>\n",
      "train_loss: 0.045694, train_accuracy: 40.7185%, valid_loss: 0.046619, valid_accuracy: 39.8263%\n",
      "EarlyStopping counter: 3 out of 20\n",
      "epoch:  16 <2024-02-17 17:41:17>\n",
      "train_loss: 0.046024, train_accuracy: 40.8271%, valid_loss: 0.046384, valid_accuracy: 41.1627%\n",
      "EarlyStopping counter: 4 out of 20\n",
      "epoch:  17 <2024-02-17 17:44:21>\n",
      "train_loss: 0.046234, train_accuracy: 40.1504%, valid_loss: 0.046280, valid_accuracy: 41.5971%\n",
      "EarlyStopping counter: 5 out of 20\n",
      "epoch:  18 <2024-02-17 17:47:22>\n",
      "train_loss: 0.046718, train_accuracy: 40.5013%, valid_loss: 0.048856, valid_accuracy: 37.7213%\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-04.\n",
      "EarlyStopping counter: 6 out of 20\n",
      "epoch:  19 <2024-02-17 17:50:23>\n",
      "train_loss: 0.044375, train_accuracy: 42.8488%, valid_loss: 0.045069, valid_accuracy: 42.2319%\n",
      "Validation loss decreased (0.045495 --> 0.045069).  Saving model ...\n",
      "epoch:  20 <2024-02-17 17:53:26>\n",
      "train_loss: 0.044227, train_accuracy: 42.9992%, valid_loss: 0.045036, valid_accuracy: 42.5326%\n",
      "Validation loss decreased (0.045069 --> 0.045036).  Saving model ...\n",
      "epoch:  21 <2024-02-17 17:56:28>\n",
      "train_loss: 0.043926, train_accuracy: 44.3442%, valid_loss: 0.045580, valid_accuracy: 40.8954%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:  22 <2024-02-17 17:59:31>\n",
      "train_loss: 0.044062, train_accuracy: 43.2581%, valid_loss: 0.045111, valid_accuracy: 41.8644%\n",
      "EarlyStopping counter: 2 out of 20\n",
      "epoch:  23 <2024-02-17 18:02:34>\n",
      "train_loss: 0.044033, train_accuracy: 43.4921%, valid_loss: 0.045212, valid_accuracy: 41.7307%\n",
      "EarlyStopping counter: 3 out of 20\n",
      "epoch:  24 <2024-02-17 18:05:36>\n",
      "train_loss: 0.044021, train_accuracy: 44.0351%, valid_loss: 0.045325, valid_accuracy: 41.8978%\n",
      "EarlyStopping counter: 4 out of 20\n",
      "epoch:  25 <2024-02-17 18:08:38>\n",
      "train_loss: 0.044182, train_accuracy: 42.8154%, valid_loss: 0.045298, valid_accuracy: 41.6973%\n",
      "EarlyStopping counter: 5 out of 20\n",
      "epoch:  26 <2024-02-17 18:11:41>\n",
      "train_loss: 0.044027, train_accuracy: 43.2080%, valid_loss: 0.045202, valid_accuracy: 42.2987%\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.0000e-05.\n",
      "EarlyStopping counter: 6 out of 20\n",
      "epoch:  27 <2024-02-17 18:14:46>\n",
      "train_loss: 0.043506, train_accuracy: 43.8429%, valid_loss: 0.045120, valid_accuracy: 42.2319%\n",
      "EarlyStopping counter: 7 out of 20\n",
      "epoch:  28 <2024-02-17 18:17:51>\n",
      "train_loss: 0.043562, train_accuracy: 44.4361%, valid_loss: 0.045170, valid_accuracy: 41.9980%\n",
      "EarlyStopping counter: 8 out of 20\n",
      "epoch:  29 <2024-02-17 18:20:53>\n",
      "train_loss: 0.043567, train_accuracy: 44.4361%, valid_loss: 0.045041, valid_accuracy: 42.4658%\n",
      "EarlyStopping counter: 9 out of 20\n",
      "epoch:  30 <2024-02-17 18:23:55>\n",
      "train_loss: 0.043550, train_accuracy: 44.5614%, valid_loss: 0.045111, valid_accuracy: 42.2319%\n",
      "EarlyStopping counter: 10 out of 20\n",
      "epoch:  31 <2024-02-17 18:26:58>\n",
      "train_loss: 0.043539, train_accuracy: 44.7786%, valid_loss: 0.045123, valid_accuracy: 42.6662%\n",
      "EarlyStopping counter: 11 out of 20\n",
      "epoch:  32 <2024-02-17 18:29:59>\n",
      "train_loss: 0.043253, train_accuracy: 44.6951%, valid_loss: 0.044854, valid_accuracy: 41.9980%\n",
      "Validation loss decreased (0.045036 --> 0.044854).  Saving model ...\n",
      "epoch:  33 <2024-02-17 18:33:01>\n",
      "train_loss: 0.043627, train_accuracy: 44.2857%, valid_loss: 0.045229, valid_accuracy: 41.9980%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:  34 <2024-02-17 18:36:00>\n",
      "train_loss: 0.043478, train_accuracy: 44.1938%, valid_loss: 0.045062, valid_accuracy: 41.7641%\n",
      "EarlyStopping counter: 2 out of 20\n",
      "epoch:  35 <2024-02-17 18:39:01>\n",
      "train_loss: 0.043471, train_accuracy: 44.5029%, valid_loss: 0.045055, valid_accuracy: 41.7307%\n",
      "EarlyStopping counter: 3 out of 20\n",
      "epoch:  36 <2024-02-17 18:42:02>\n",
      "train_loss: 0.043642, train_accuracy: 43.9348%, valid_loss: 0.045040, valid_accuracy: 41.5971%\n",
      "EarlyStopping counter: 4 out of 20\n",
      "epoch:  37 <2024-02-17 18:45:04>\n",
      "train_loss: 0.043374, train_accuracy: 44.5196%, valid_loss: 0.045059, valid_accuracy: 42.7665%\n",
      "EarlyStopping counter: 5 out of 20\n",
      "epoch:  38 <2024-02-17 18:48:04>\n",
      "train_loss: 0.043443, train_accuracy: 44.3776%, valid_loss: 0.045062, valid_accuracy: 41.4968%\n",
      "Epoch 00038: reducing learning rate of group 0 to 1.0000e-06.\n",
      "EarlyStopping counter: 6 out of 20\n",
      "epoch:  39 <2024-02-17 18:51:06>\n",
      "train_loss: 0.043523, train_accuracy: 43.9766%, valid_loss: 0.045000, valid_accuracy: 42.3321%\n",
      "EarlyStopping counter: 7 out of 20\n",
      "epoch:  40 <2024-02-17 18:54:08>\n",
      "train_loss: 0.043408, train_accuracy: 44.4444%, valid_loss: 0.045127, valid_accuracy: 41.7307%\n",
      "EarlyStopping counter: 8 out of 20\n",
      "epoch:  41 <2024-02-17 18:57:11>\n",
      "train_loss: 0.043485, train_accuracy: 44.6449%, valid_loss: 0.045051, valid_accuracy: 42.5660%\n",
      "EarlyStopping counter: 9 out of 20\n",
      "epoch:  42 <2024-02-17 19:00:14>\n",
      "train_loss: 0.043352, train_accuracy: 44.5029%, valid_loss: 0.045128, valid_accuracy: 42.3655%\n",
      "EarlyStopping counter: 10 out of 20\n",
      "epoch:  43 <2024-02-17 19:03:14>\n",
      "train_loss: 0.043295, train_accuracy: 44.8454%, valid_loss: 0.045170, valid_accuracy: 41.9646%\n",
      "EarlyStopping counter: 11 out of 20\n",
      "epoch:  44 <2024-02-17 19:06:17>\n",
      "train_loss: 0.043292, train_accuracy: 44.5948%, valid_loss: 0.044921, valid_accuracy: 42.6662%\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.0000e-07.\n",
      "EarlyStopping counter: 12 out of 20\n",
      "epoch:  45 <2024-02-17 19:09:17>\n",
      "train_loss: 0.043542, train_accuracy: 44.4612%, valid_loss: 0.044949, valid_accuracy: 42.5326%\n",
      "EarlyStopping counter: 13 out of 20\n",
      "epoch:  46 <2024-02-17 19:12:18>\n",
      "train_loss: 0.043392, train_accuracy: 44.6282%, valid_loss: 0.045270, valid_accuracy: 41.2629%\n",
      "EarlyStopping counter: 14 out of 20\n",
      "epoch:  47 <2024-02-17 19:15:20>\n",
      "train_loss: 0.043389, train_accuracy: 44.4110%, valid_loss: 0.045010, valid_accuracy: 42.3655%\n",
      "EarlyStopping counter: 15 out of 20\n",
      "epoch:  48 <2024-02-17 19:18:24>\n",
      "train_loss: 0.043465, train_accuracy: 44.4027%, valid_loss: 0.044945, valid_accuracy: 41.6639%\n",
      "EarlyStopping counter: 16 out of 20\n",
      "epoch:  49 <2024-02-17 19:21:30>\n",
      "train_loss: 0.043218, train_accuracy: 44.6449%, valid_loss: 0.045124, valid_accuracy: 41.5302%\n",
      "EarlyStopping counter: 17 out of 20\n",
      "epoch:  50 <2024-02-17 19:24:45>\n",
      "train_loss: 0.043371, train_accuracy: 44.0017%, valid_loss: 0.044805, valid_accuracy: 41.7641%\n",
      "Validation loss decreased (0.044854 --> 0.044805).  Saving model ...\n",
      "epoch:  51 <2024-02-17 19:27:52>\n",
      "train_loss: 0.043423, train_accuracy: 44.2857%, valid_loss: 0.045205, valid_accuracy: 41.4968%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:  52 <2024-02-17 19:31:34>\n",
      "train_loss: 0.043450, train_accuracy: 44.2189%, valid_loss: 0.045111, valid_accuracy: 41.9980%\n",
      "EarlyStopping counter: 2 out of 20\n",
      "epoch:  53 <2024-02-17 19:34:40>\n",
      "train_loss: 0.043489, train_accuracy: 44.4110%, valid_loss: 0.045223, valid_accuracy: 42.5326%\n",
      "EarlyStopping counter: 3 out of 20\n",
      "epoch:  54 <2024-02-17 19:37:46>\n",
      "train_loss: 0.043309, train_accuracy: 44.7118%, valid_loss: 0.045198, valid_accuracy: 41.8978%\n",
      "EarlyStopping counter: 4 out of 20\n",
      "epoch:  55 <2024-02-17 19:40:51>\n",
      "train_loss: 0.043322, train_accuracy: 44.4612%, valid_loss: 0.044913, valid_accuracy: 42.0982%\n",
      "EarlyStopping counter: 5 out of 20\n",
      "epoch:  56 <2024-02-17 19:43:55>\n",
      "train_loss: 0.043431, train_accuracy: 44.6366%, valid_loss: 0.045321, valid_accuracy: 41.9646%\n",
      "Epoch 00056: reducing learning rate of group 0 to 1.0000e-08.\n",
      "EarlyStopping counter: 6 out of 20\n",
      "epoch:  57 <2024-02-17 19:46:59>\n",
      "train_loss: 0.043362, train_accuracy: 44.5698%, valid_loss: 0.044952, valid_accuracy: 42.1316%\n",
      "EarlyStopping counter: 7 out of 20\n",
      "epoch:  58 <2024-02-17 19:50:02>\n",
      "train_loss: 0.043384, train_accuracy: 44.5196%, valid_loss: 0.045218, valid_accuracy: 41.4634%\n",
      "EarlyStopping counter: 8 out of 20\n",
      "epoch:  59 <2024-02-17 19:53:05>\n",
      "train_loss: 0.043531, train_accuracy: 44.2356%, valid_loss: 0.045107, valid_accuracy: 41.9312%\n",
      "EarlyStopping counter: 9 out of 20\n",
      "epoch:  60 <2024-02-17 19:56:11>\n",
      "train_loss: 0.043322, train_accuracy: 44.5614%, valid_loss: 0.044908, valid_accuracy: 42.7999%\n",
      "EarlyStopping counter: 10 out of 20\n",
      "epoch:  61 <2024-02-17 19:59:16>\n",
      "train_loss: 0.043493, train_accuracy: 44.2774%, valid_loss: 0.045306, valid_accuracy: 41.7641%\n",
      "EarlyStopping counter: 11 out of 20\n",
      "epoch:  62 <2024-02-17 20:02:19>\n",
      "train_loss: 0.043335, train_accuracy: 44.3442%, valid_loss: 0.044974, valid_accuracy: 42.2319%\n",
      "EarlyStopping counter: 12 out of 20\n",
      "epoch:  63 <2024-02-17 20:05:24>\n",
      "train_loss: 0.043374, train_accuracy: 44.3108%, valid_loss: 0.044994, valid_accuracy: 41.6973%\n",
      "EarlyStopping counter: 13 out of 20\n",
      "epoch:  64 <2024-02-17 20:08:28>\n",
      "train_loss: 0.043398, train_accuracy: 44.6032%, valid_loss: 0.045058, valid_accuracy: 42.3989%\n",
      "EarlyStopping counter: 14 out of 20\n",
      "epoch:  65 <2024-02-17 20:11:33>\n",
      "train_loss: 0.043481, train_accuracy: 44.3108%, valid_loss: 0.045230, valid_accuracy: 42.0648%\n",
      "EarlyStopping counter: 15 out of 20\n",
      "epoch:  66 <2024-02-17 20:14:39>\n",
      "train_loss: 0.043348, train_accuracy: 44.4277%, valid_loss: 0.044896, valid_accuracy: 42.3989%\n",
      "EarlyStopping counter: 16 out of 20\n",
      "epoch:  67 <2024-02-17 20:17:45>\n",
      "train_loss: 0.043468, train_accuracy: 44.3860%, valid_loss: 0.045012, valid_accuracy: 41.9646%\n",
      "EarlyStopping counter: 17 out of 20\n",
      "epoch:  68 <2024-02-17 20:20:53>\n",
      "train_loss: 0.043315, train_accuracy: 44.9123%, valid_loss: 0.044955, valid_accuracy: 41.9646%\n",
      "EarlyStopping counter: 18 out of 20\n",
      "epoch:  69 <2024-02-17 20:24:33>\n",
      "train_loss: 0.043394, train_accuracy: 44.5029%, valid_loss: 0.044788, valid_accuracy: 41.9980%\n",
      "Validation loss decreased (0.044805 --> 0.044788).  Saving model ...\n",
      "epoch:  70 <2024-02-17 20:27:38>\n",
      "train_loss: 0.043592, train_accuracy: 44.2857%, valid_loss: 0.045134, valid_accuracy: 42.1985%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:  71 <2024-02-17 20:30:41>\n",
      "train_loss: 0.043503, train_accuracy: 44.0852%, valid_loss: 0.045066, valid_accuracy: 42.2653%\n",
      "EarlyStopping counter: 2 out of 20\n",
      "epoch:  72 <2024-02-17 20:33:46>\n",
      "train_loss: 0.043276, train_accuracy: 44.7118%, valid_loss: 0.044904, valid_accuracy: 42.1985%\n",
      "EarlyStopping counter: 3 out of 20\n",
      "epoch:  73 <2024-02-17 20:36:53>\n",
      "train_loss: 0.043564, train_accuracy: 44.2356%, valid_loss: 0.044807, valid_accuracy: 42.4992%\n",
      "EarlyStopping counter: 4 out of 20\n",
      "epoch:  74 <2024-02-17 20:39:59>\n",
      "train_loss: 0.043499, train_accuracy: 44.4862%, valid_loss: 0.044852, valid_accuracy: 42.2653%\n",
      "EarlyStopping counter: 5 out of 20\n",
      "epoch:  75 <2024-02-17 20:43:04>\n",
      "train_loss: 0.043397, train_accuracy: 44.1437%, valid_loss: 0.045130, valid_accuracy: 41.8644%\n",
      "EarlyStopping counter: 6 out of 20\n",
      "epoch:  76 <2024-02-17 20:46:09>\n",
      "train_loss: 0.043288, train_accuracy: 44.3860%, valid_loss: 0.045331, valid_accuracy: 41.8644%\n",
      "EarlyStopping counter: 7 out of 20\n",
      "epoch:  77 <2024-02-17 20:49:15>\n",
      "train_loss: 0.043531, train_accuracy: 44.5865%, valid_loss: 0.044965, valid_accuracy: 42.5994%\n",
      "EarlyStopping counter: 8 out of 20\n",
      "epoch:  78 <2024-02-17 20:52:20>\n",
      "train_loss: 0.043388, train_accuracy: 44.3693%, valid_loss: 0.045162, valid_accuracy: 42.0648%\n",
      "EarlyStopping counter: 9 out of 20\n",
      "epoch:  79 <2024-02-17 20:55:27>\n",
      "train_loss: 0.043450, train_accuracy: 44.4779%, valid_loss: 0.044771, valid_accuracy: 42.1985%\n",
      "Validation loss decreased (0.044788 --> 0.044771).  Saving model ...\n",
      "epoch:  80 <2024-02-17 20:58:36>\n",
      "train_loss: 0.043294, train_accuracy: 44.2439%, valid_loss: 0.044951, valid_accuracy: 42.0982%\n",
      "EarlyStopping counter: 1 out of 20\n",
      "epoch:  81 <2024-02-17 21:01:43>\n",
      "train_loss: 0.043284, train_accuracy: 44.5363%, valid_loss: 0.044788, valid_accuracy: 42.0314%\n",
      "EarlyStopping counter: 2 out of 20\n",
      "epoch:  82 <2024-02-17 21:04:51>\n",
      "train_loss: 0.043409, train_accuracy: 44.5698%, valid_loss: 0.045129, valid_accuracy: 41.7307%\n",
      "EarlyStopping counter: 3 out of 20\n",
      "epoch:  83 <2024-02-17 21:07:57>\n",
      "train_loss: 0.043459, train_accuracy: 44.3693%, valid_loss: 0.044900, valid_accuracy: 42.0648%\n",
      "EarlyStopping counter: 4 out of 20\n",
      "epoch:  84 <2024-02-17 21:11:02>\n",
      "train_loss: 0.043422, train_accuracy: 44.3609%, valid_loss: 0.045001, valid_accuracy: 42.4323%\n",
      "EarlyStopping counter: 5 out of 20\n",
      "epoch:  85 <2024-02-17 21:14:08>\n",
      "train_loss: 0.043336, train_accuracy: 44.3609%, valid_loss: 0.044972, valid_accuracy: 42.2319%\n",
      "EarlyStopping counter: 6 out of 20\n",
      "epoch:  86 <2024-02-17 21:17:13>\n",
      "train_loss: 0.043506, train_accuracy: 44.2774%, valid_loss: 0.045265, valid_accuracy: 41.8644%\n",
      "EarlyStopping counter: 7 out of 20\n",
      "epoch:  87 <2024-02-17 21:20:19>\n",
      "train_loss: 0.043490, train_accuracy: 43.8847%, valid_loss: 0.044972, valid_accuracy: 41.9980%\n",
      "EarlyStopping counter: 8 out of 20\n",
      "epoch:  88 <2024-02-17 21:23:24>\n",
      "train_loss: 0.043332, train_accuracy: 44.2774%, valid_loss: 0.045160, valid_accuracy: 42.0648%\n",
      "EarlyStopping counter: 9 out of 20\n",
      "epoch:  89 <2024-02-17 21:26:31>\n",
      "train_loss: 0.043372, train_accuracy: 43.9515%, valid_loss: 0.044906, valid_accuracy: 42.1316%\n",
      "EarlyStopping counter: 10 out of 20\n",
      "epoch:  90 <2024-02-17 21:29:36>\n",
      "train_loss: 0.043556, train_accuracy: 44.7619%, valid_loss: 0.045065, valid_accuracy: 42.1316%\n",
      "EarlyStopping counter: 11 out of 20\n",
      "epoch:  91 <2024-02-17 21:32:42>\n",
      "train_loss: 0.043345, train_accuracy: 44.4528%, valid_loss: 0.045159, valid_accuracy: 42.4992%\n",
      "EarlyStopping counter: 12 out of 20\n",
      "epoch:  92 <2024-02-17 21:35:47>\n",
      "train_loss: 0.043433, train_accuracy: 44.1855%, valid_loss: 0.045146, valid_accuracy: 42.6996%\n",
      "EarlyStopping counter: 13 out of 20\n",
      "epoch:  93 <2024-02-17 21:38:52>\n",
      "train_loss: 0.043472, train_accuracy: 44.5698%, valid_loss: 0.045131, valid_accuracy: 41.9312%\n",
      "EarlyStopping counter: 14 out of 20\n",
      "epoch:  94 <2024-02-17 21:41:57>\n",
      "train_loss: 0.043378, train_accuracy: 44.2607%, valid_loss: 0.044907, valid_accuracy: 42.5326%\n",
      "EarlyStopping counter: 15 out of 20\n",
      "epoch:  95 <2024-02-17 21:45:03>\n",
      "train_loss: 0.043426, train_accuracy: 44.4361%, valid_loss: 0.045228, valid_accuracy: 42.0648%\n",
      "EarlyStopping counter: 16 out of 20\n",
      "epoch:  96 <2024-02-17 21:48:09>\n",
      "train_loss: 0.043394, train_accuracy: 44.0100%, valid_loss: 0.045103, valid_accuracy: 42.3321%\n",
      "EarlyStopping counter: 17 out of 20\n",
      "epoch:  97 <2024-02-17 21:51:14>\n",
      "train_loss: 0.043485, train_accuracy: 44.1771%, valid_loss: 0.045313, valid_accuracy: 41.9646%\n",
      "EarlyStopping counter: 18 out of 20\n",
      "epoch:  98 <2024-02-17 21:54:19>\n",
      "train_loss: 0.043306, train_accuracy: 44.6951%, valid_loss: 0.044980, valid_accuracy: 41.4634%\n",
      "EarlyStopping counter: 19 out of 20\n",
      "epoch:  99 <2024-02-17 21:57:24>\n",
      "train_loss: 0.043617, train_accuracy: 43.8095%, valid_loss: 0.045311, valid_accuracy: 41.6973%\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "## 学習開始\n",
    "\n",
    "train_dataset = ImgValueDataset( train_df ,classcol=labels_cols , fncol='filepath',extendcol = extend_cols , transform=transform_train)\n",
    "test_dataset = ImgValueDataset( test_df ,classcol=labels_cols , fncol='filepath' ,extendcol = extend_cols ,transform=transform_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "net = createMyNet().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "## 5エポック改善がみなれないと\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "EPOCHS = 300\n",
    "trainset = [train_loader,test_loader]\n",
    "\n",
    "history = do_train_and_validate(net, trainset, criterion, optimizer, scheduler,EPOCHS,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ebd9a-bbfe-44f7-a437-5119d9ed677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgValueDataset(Dataset):\n",
    "    def __getitem__(self, index):\n",
    "        # 画像をPILとして読み込む\n",
    "        image = Image.open(self.img_pathlist[index])\n",
    "        #　ラベル\n",
    "        label = self.label_list[index]\n",
    "        # 数値データ\n",
    "        extend = self.val_list[index]                         \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        ## 次元を足してそこに追加データを結合\n",
    "        extend_tensor = np.full((224,224),255)\n",
    "        extend_tensor[1][0] = extend[0]\n",
    "        extend_tensor[1][1] = extend[1]\n",
    "        extend_tensor[1][2] = extend[2]\n",
    "        #print(extend_tensor)\n",
    "        extend_tensor = torch.Tensor(extend_tensor)\n",
    "        extend_tensor = extend_tensor.unsqueeze(0)\n",
    "        out = torch.cat([image, extend_tensor], dim=0)\n",
    "                             \n",
    "        return out, label \n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
