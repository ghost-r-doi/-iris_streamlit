{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4b3af0-8796-4f91-a3b8-a189ed4b5b47",
   "metadata": {},
   "source": [
    "# 自前のネットワークを組んで学習させてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7703dc5b-ee9d-4aaa-add2-f96d5029ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41647b1b-afa7-4fd6-ae50-20a1694f1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = r'./dataset_cur_train.csv'\n",
    "test_fn = r'./dataset_cur_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55fd0446-9e09-443b-9a85-463eec4bdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir_path_recursive = './myInspectionV3/'\n",
    "os.makedirs(new_dir_path_recursive, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5294d05-3e0d-461d-83fc-16ebda6d1449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "redpoint_-3            int64\n",
       "redpoint_-2            int64\n",
       "redpoint_-1            int64\n",
       "redpoint_0             int64\n",
       "redpoint_1             int64\n",
       "redpoint_2             int64\n",
       "redpoint_3             int64\n",
       "pred                   int64\n",
       "ends                   int64\n",
       "red                  float64\n",
       "yellow               float64\n",
       "red_diff             float32\n",
       "remain_ends          float32\n",
       "last_stone_is_red    float32\n",
       "red_postion          float32\n",
       "filepath              object\n",
       "page                   int64\n",
       "T                     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "      <th>pred</th>\n",
       "      <th>ends</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "      <th>page</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...</td>\n",
       "      <td>462</td>\n",
       "      <td>ECC2023_ResultsBook_Women_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...</td>\n",
       "      <td>318</td>\n",
       "      <td>CWC2018-19_Leg3_ResultsBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png</td>\n",
       "      <td>600</td>\n",
       "      <td>WWCC2022_ResultsBook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "2            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  pred  ends  red  yellow  red_diff  remain_ends  \\\n",
       "0           0    -3     4  0.0     3.0      -3.0          5.0   \n",
       "1           0     1     7  1.0     0.0       1.0          2.0   \n",
       "2           0     1     4  1.0     0.0       1.0          5.0   \n",
       "\n",
       "   last_stone_is_red  red_postion  \\\n",
       "0                0.0         -3.0   \n",
       "1                1.0          3.0   \n",
       "2                1.0          0.0   \n",
       "\n",
       "                                            filepath  page  \\\n",
       "0  ./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...   462   \n",
       "1  ./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...   318   \n",
       "2   ./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png   600   \n",
       "\n",
       "                                      T  \n",
       "0  ECC2023_ResultsBook_Women_A-Division  \n",
       "1           CWC2018-19_Leg3_ResultsBook  \n",
       "2                  WWCC2022_ResultsBook  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_fn,index_col=0)\n",
    "df_train['red_diff'] = df_train['red_diff'].astype(np.float32)\n",
    "df_train['remain_ends'] = df_train['remain_ends'].astype(np.float32)\n",
    "df_train['last_stone_is_red'] = df_train['last_stone_is_red'].astype(np.float32)\n",
    "df_train['red_postion'] = df_train['red_postion'].astype(np.float32)\n",
    "display(df_train.dtypes)\n",
    "display(df_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416d239-816d-4246-98c9-68aa35baafb0",
   "metadata": {},
   "source": [
    "## red_diff&red_point が目的、fn,remain_ends,last_stone_is_red,red_postion が説明変数\n",
    "説明変数を標準化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa9751-11cd-40b2-a6c4-1ae948374df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba7ce319-2e82-424f-94ff-2a6171635c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3675206 , -1.0015383 , -1.2659631 ],\n",
       "       [-0.78656346,  0.99846405,  1.2369138 ],\n",
       "       [ 0.3675206 ,  0.99846405, -0.0145247 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([4.04464345, 0.50076856, 0.03481922])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([6.757213  , 0.24999941, 5.74676597])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "      <th>pred</th>\n",
       "      <th>ends</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "      <th>page</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>-1.001538</td>\n",
       "      <td>-1.265963</td>\n",
       "      <td>./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...</td>\n",
       "      <td>462</td>\n",
       "      <td>ECC2023_ResultsBook_Women_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.786563</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>1.236914</td>\n",
       "      <td>./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...</td>\n",
       "      <td>318</td>\n",
       "      <td>CWC2018-19_Leg3_ResultsBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>-0.014525</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png</td>\n",
       "      <td>600</td>\n",
       "      <td>WWCC2022_ResultsBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.171258</td>\n",
       "      <td>-1.001538</td>\n",
       "      <td>1.654060</td>\n",
       "      <td>./dataset_o\\ECC2022_ResultsBook_Men_A-Division...</td>\n",
       "      <td>23</td>\n",
       "      <td>ECC2022_ResultsBook_Men_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.171258</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>-0.848817</td>\n",
       "      <td>./dataset_o\\WWCC2018_ResultsBook\\geme722end8.png</td>\n",
       "      <td>722</td>\n",
       "      <td>WWCC2018_ResultsBook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "2            0            0            0           0           1           0   \n",
       "3            0            1            0           0           0           0   \n",
       "4            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  pred  ends  red  yellow  red_diff  remain_ends  \\\n",
       "0           0    -3     4  0.0     3.0      -3.0     0.367521   \n",
       "1           0     1     7  1.0     0.0       1.0    -0.786563   \n",
       "2           0     1     4  1.0     0.0       1.0     0.367521   \n",
       "3           0    -2     8  0.0     2.0      -2.0    -1.171258   \n",
       "4           0     1     8  1.0     0.0       1.0    -1.171258   \n",
       "\n",
       "   last_stone_is_red  red_postion  \\\n",
       "0          -1.001538    -1.265963   \n",
       "1           0.998464     1.236914   \n",
       "2           0.998464    -0.014525   \n",
       "3          -1.001538     1.654060   \n",
       "4           0.998464    -0.848817   \n",
       "\n",
       "                                            filepath  page  \\\n",
       "0  ./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...   462   \n",
       "1  ./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...   318   \n",
       "2   ./dataset_o\\WWCC2022_ResultsBook\\geme600end4.png   600   \n",
       "3  ./dataset_o\\ECC2022_ResultsBook_Men_A-Division...    23   \n",
       "4   ./dataset_o\\WWCC2018_ResultsBook\\geme722end8.png   722   \n",
       "\n",
       "                                      T  \n",
       "0  ECC2023_ResultsBook_Women_A-Division  \n",
       "1           CWC2018-19_Leg3_ResultsBook  \n",
       "2                  WWCC2022_ResultsBook  \n",
       "3    ECC2022_ResultsBook_Men_A-Division  \n",
       "4                  WWCC2018_ResultsBook  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化\n",
    "stdsc = StandardScaler()\n",
    "##学習時の標準化したパラメータは、評価、本番時におなじ重みで標準化する処理が必要\n",
    "x_train_df  = df_train[['remain_ends','last_stone_is_red','red_postion']].copy()\n",
    "x_train_std = stdsc.fit_transform(x_train_df)\n",
    "display( x_train_std[:3] )\n",
    "display(stdsc.n_features_in_, stdsc.mean_ , stdsc.var_) \n",
    "pickle.dump(stdsc, open(new_dir_path_recursive+\"stdsc_02240209.pkl\", \"wb\"))\n",
    "\n",
    "df_train[['remain_ends','last_stone_is_red','red_postion']] = x_train_std\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a26fa-baaf-42e8-9364-5c7b6e3c9a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "232f4a74-d1e7-4304-a0f7-933485b4a9ba",
   "metadata": {},
   "source": [
    "### InspectionV3\n",
    "https://pytorch.org/vision/main/models/inception.html   \n",
    "crop = 342\n",
    "mean=[0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc251581-3052-406f-94bf-c781ea7943a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    ##torch.backends.cudnn.deterministic = True\n",
    "    ##torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d98501e-1d3d-4b23-bb83-646cf5a3f981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 540]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 画像変換の定義\n",
    "w,h = Image.open(df_train['filepath'].values[0]).size\n",
    "## 正方形にするための差分\n",
    "pad = (h-w)/2\n",
    "display([w,h],pad)\n",
    "target_size = 342\n",
    "## train用\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# valid/test用\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22f5154d-84a6-42eb-b638-dbab73d94516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3     841\n",
       " -2    2032\n",
       " -1    3619\n",
       "  0    1807\n",
       "  1    3720\n",
       "  2    2115\n",
       "  3     829\n",
       " dtype: int64,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_data = pd.get_dummies(df_train['pred'])\n",
    "class_data.sum() , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7879ed0-c0bc-4169-9ded-dc208041cdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['redpoint_-3',\n",
       " 'redpoint_-2',\n",
       " 'redpoint_-1',\n",
       " 'redpoint_0',\n",
       " 'redpoint_1',\n",
       " 'redpoint_2',\n",
       " 'redpoint_3']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  \n",
       "0           0  \n",
       "1           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_cols = list(filter( lambda s:s.startswith('redpoint_'),  df_train.columns))\n",
    "display(labels_cols , df_train[labels_cols][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed388034-7646-46b5-aefb-09880fa1571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_cols = ['remain_ends','last_stone_is_red','red_postion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f773c-6504-40e9-a103-bd8b100ab1a2",
   "metadata": {},
   "source": [
    "# 自前のデータセット定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f04521e7-c7bd-4a5d-9a0c-71a00502dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgValueDataset(Dataset):\n",
    "    def __init__(self, df, classcol , fncol ,extendcol, transform):\n",
    "        \n",
    "        self.img_pathlist = df[fncol].values\n",
    "        \n",
    "        class_data = df[classcol].values\n",
    "        self.label_list  = class_data.astype(float)\n",
    "        \n",
    "        self.val_list  = df[extendcol].astype(np.float16).values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len( self.img_pathlist )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 画像をPILとして読み込む\n",
    "        #print(index,self.img_pathlist[index])\n",
    "        image = Image.open(self.img_pathlist[index])\n",
    "        \n",
    "        label = self.label_list[index]\n",
    "\n",
    "        extend = self.val_list[index]                         \n",
    "        if self.transform is not None:\n",
    "            ##print('use transform')\n",
    "            image = self.transform(image)\n",
    "        ## 次元を足してやってっそこに追加データをぶっこむ\n",
    "        extend_tensor = np.full((target_size,target_size),255)\n",
    "        extend_tensor[1][0] = extend[0]\n",
    "        extend_tensor[1][1] = extend[1]\n",
    "        extend_tensor[1][2] = extend[2]\n",
    "        #print(extend_tensor)\n",
    "        extend_tensor = torch.Tensor(extend_tensor)\n",
    "        extend_tensor = extend_tensor.unsqueeze(0)\n",
    "        out = torch.cat([image, extend_tensor], dim=0)\n",
    "                             \n",
    "        return out, label \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d21f2ff-a686-4a02-9e5a-8dae8ed9f844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redpoint_-3</th>\n",
       "      <th>redpoint_-2</th>\n",
       "      <th>redpoint_-1</th>\n",
       "      <th>redpoint_0</th>\n",
       "      <th>redpoint_1</th>\n",
       "      <th>redpoint_2</th>\n",
       "      <th>redpoint_3</th>\n",
       "      <th>pred</th>\n",
       "      <th>ends</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "      <th>page</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>-1.001538</td>\n",
       "      <td>-1.265963</td>\n",
       "      <td>./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...</td>\n",
       "      <td>462</td>\n",
       "      <td>ECC2023_ResultsBook_Women_A-Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.786563</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>1.236914</td>\n",
       "      <td>./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...</td>\n",
       "      <td>318</td>\n",
       "      <td>CWC2018-19_Leg3_ResultsBook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   redpoint_-3  redpoint_-2  redpoint_-1  redpoint_0  redpoint_1  redpoint_2  \\\n",
       "0            1            0            0           0           0           0   \n",
       "1            0            0            0           0           1           0   \n",
       "\n",
       "   redpoint_3  pred  ends  red  yellow  red_diff  remain_ends  \\\n",
       "0           0    -3     4  0.0     3.0      -3.0     0.367521   \n",
       "1           0     1     7  1.0     0.0       1.0    -0.786563   \n",
       "\n",
       "   last_stone_is_red  red_postion  \\\n",
       "0          -1.001538    -1.265963   \n",
       "1           0.998464     1.236914   \n",
       "\n",
       "                                            filepath  page  \\\n",
       "0  ./dataset_o\\ECC2023_ResultsBook_Women_A-Divisi...   462   \n",
       "1  ./dataset_o\\CWC2018-19_Leg3_ResultsBook\\geme31...   318   \n",
       "\n",
       "                                      T  \n",
       "0  ECC2023_ResultsBook_Women_A-Division  \n",
       "1           CWC2018-19_Leg3_ResultsBook  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1a795a1-a4b0-4f93-bb8d-9544cce15f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['redpoint_-3',\n",
       "  'redpoint_-2',\n",
       "  'redpoint_-1',\n",
       "  'redpoint_0',\n",
       "  'redpoint_1',\n",
       "  'redpoint_2',\n",
       "  'redpoint_3'],\n",
       " ['remain_ends', 'last_stone_is_red', 'red_postion'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_train, test_size=0.2, stratify=df_train['pred'])\n",
    "labels_cols,extend_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17254037-db32-49a6-bd17-e1c2101da310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11970, 2993)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ImgValueDataset( train_df ,classcol=labels_cols , fncol='filepath',extendcol = extend_cols , transform=transform_train)\n",
    "test_dataset = ImgValueDataset( test_df ,classcol=labels_cols , fncol='filepath' ,extendcol = extend_cols ,transform=transform_test)\n",
    "len(train_df) , len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a9aa0e0-f19c-4983-846a-4fb6955f5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f12baa4-eaf9-43e9-aed0-30be6dabc706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2993"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b80edabd-3b50-49e8-aec9-88cb63cfa1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 342, 342]),\n",
       " tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels  = next(iter(train_loader))\n",
    "inputs.shape , labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "409e018e-0b4b-4b1a-9364-347f19600945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,  -1.,   0., 255., 255.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#分割テスト\n",
    "one_sampe = inputs[2,]\n",
    "p = torchvision.transforms.functional.to_pil_image(one_sampe[0:2])\n",
    "fig,ax=plt.subplots(1,1,figsize=(2,2))\n",
    "plt.imshow(p) \n",
    "one_sampe[3,1,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f0cda-b0ce-4e75-a54d-7cbc9ac14da9",
   "metadata": {},
   "source": [
    "# ネットを組む  \n",
    "https://qiita.com/poorko/items/c151ff4a827f114fe954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5020444e-2c32-49c1-ad66-ef1f25ec37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e13e5752-aa83-4961-bc43-206295071cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghost\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ghost\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ghost\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./myInspectionV3\\inception_v3_google-0cc3c7bd.pth\n",
      "<class 'torchvision.models.inception.Inception3'> tensor([-0.2239, -0.4473, -0.0314,  0.0991,  0.5365,  0.0507,  0.1138, -0.4573,\n",
      "        -0.4628, -0.1953], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.inception_v3(pretrained=False)\n",
    "g = glob.glob(new_dir_path_recursive + 'inception_v3*.pth')\n",
    "fn = g[0]\n",
    "print(fn)\n",
    "model_ft.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc.bias[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e80e3677-aec5-4ee1-89c8-3477082cf25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.inception.Inception3'> tensor([-0.2239, -0.4473, -0.0314,  0.0991,  0.5365,  0.0507,  0.1138, -0.4573,\n",
      "        -0.4628, -0.1953], grad_fn=<SliceBackward0>)\n",
      "すべてのネットの重みをロック [ True]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.inception import Inception3\n",
    "net = Inception3()\n",
    "net.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc.bias[:10] )\n",
    "\n",
    "for i, param in enumerate(net.parameters()):\n",
    "        param.requires_grad = True #False\n",
    "x = [ param.requires_grad for param in net.parameters()]\n",
    "print('すべてのネットの重みをロック',np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9071b23-251b-41aa-94c9-4af1a7eeda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "##派生がうまくいって重みが入るかチェック\n",
    "class _myinceptionV3(models.inception.Inception3):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(_myinceptionV3)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0683e0d-6e78-4268-aacd-6418819cab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__._myinceptionV3'>\n",
      "<class 'torchvision.models.inception.Inception3'> tensor([-0.2239, -0.4473, -0.0314,  0.0991,  0.5365,  0.0507,  0.1138, -0.4573,\n",
      "        -0.4628, -0.1953], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = _myinceptionV3()\n",
    "net.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc.bias[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b05b8046-d51d-4295-801e-ddf9b0fdf915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aa77fd16-ed06-4277-a45b-28af18165bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNモデルの定義\n",
    "from typing import Dict, List, Tuple , Optional\n",
    "class myInceptionV3(models.inception.Inception3):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def _forward(self, xpacked: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "\n",
    "        input = xpacked\n",
    "        #print('input:',input.shape)\n",
    "        x = input[:,:3]\n",
    "        \n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        ###########################################\n",
    "        params = input[:,3,1,0:3]\n",
    "        output = torch.cat([x,params],1)\n",
    "        \n",
    "        ###########################################\n",
    "        # N x 2048\n",
    "        output = self.fc(output)\n",
    "        # N x 1000 (num_classes)\n",
    "        return output, aux\n",
    "    \"\"\"\n",
    "    def forward(self, xpacked:torch.Tensor) -> torch.Tensor:\n",
    "        input = xpacked\n",
    "        #print('input:',input.shape)\n",
    "        x = input[:,:3]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        ###########################################\n",
    "        params = input[:,3,1,0:3]\n",
    "        output = torch.cat([x,params],1)\n",
    "        \n",
    "        ###########################################\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c18fba-d9ed-466b-a4cd-134d6f34db71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "47ebb57a-9899-443e-b0d4-717c55a04878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.inception.Inception3'> tensor([-0.2239, -0.4473, -0.0314,  0.0991,  0.5365,  0.0507,  0.1138, -0.4573,\n",
      "        -0.4628, -0.1953], grad_fn=<SliceBackward0>)\n",
      "すべてのネットの重みをロック [False]\n",
      "2048\n",
      "最後の一つを切り替えたので混在するのが正しい: [False  True]\n"
     ]
    }
   ],
   "source": [
    "net = myInceptionV3()\n",
    "net.load_state_dict(torch.load(g[0]))\n",
    "print(type(model_ft),model_ft.fc.bias[:10] )\n",
    "\n",
    "## 重みロック\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "x = [ param.requires_grad for param in net.parameters()]\n",
    "print('すべてのネットの重みをロック',np.unique(x))\n",
    "## 最終段を11にする\n",
    "num_ftrs = net.fc.in_features\n",
    "print(num_ftrs)\n",
    "num_class = len(labels_cols)\n",
    "## tbf\n",
    "net.fc = nn.Linear(num_ftrs+3, num_class)\n",
    "##display(net)\n",
    "x = [ param.requires_grad for param in net.parameters()]\n",
    "print('最後の一つを切り替えたので混在するのが正しい:',np.unique(x)) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df47636d-9a2d-4633-91e7-72d5cea6a3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=7, bias=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "519985fb-750b-4cc4-8fb8-0e5392d8cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 関数化して\n",
    "def createMyNet():\n",
    "    net = myInceptionV3()\n",
    "    net.load_state_dict(torch.load(g[0]))\n",
    "    \n",
    "    ## 重みロック\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "    ## 最終段をlabels_colsにする\n",
    "    num_class = len(labels_cols)\n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Linear(num_ftrs+3, num_class)\n",
    "    print('最終段',net.fc)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b142fe7-2cbb-48de-8145-194d58d8eb3c",
   "metadata": {},
   "source": [
    "https://qiita.com/ku_a_i/items/ba33c9ce3449da23b503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7faeb50a-94cd-430b-ab51-b974472b2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"earlystoppingクラス\"\"\"\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):\n",
    "        \"\"\"引数：最小値の非更新数カウンタ、表示設定、モデル格納path\"\"\"\n",
    "\n",
    "        self.patience = patience    #設定ストップカウンタ\n",
    "        self.verbose = verbose      #表示の有無\n",
    "        self.counter = 0            #現在のカウンタ値\n",
    "        self.best_score = None      #ベストスコア\n",
    "        self.early_stop = False     #ストップフラグ\n",
    "        self.val_loss_min = np.Inf   #前回のベストスコア記憶用\n",
    "        self.path = path             #ベストモデル格納path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        特殊(call)メソッド\n",
    "        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n",
    "        \"\"\"\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  #1Epoch目の処理\n",
    "            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する\n",
    "            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する\n",
    "        elif score < self.best_score:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1   #ストップカウンタを+1\n",
    "            if self.verbose:  #表示を有効にした場合は経過を表示\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する \n",
    "            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "        else:  #ベストスコアを更新した場合\n",
    "            self.best_score = score  #ベストスコアを上書き\n",
    "            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示\n",
    "            self.counter = 0  #ストップカウンタリセット\n",
    "\n",
    "    def checkpoint(self, val_loss, model):\n",
    "        '''ベストスコア更新時に実行されるチェックポイント関数'''\n",
    "        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  #ベストモデルを指定したpathに保存\n",
    "        self.val_loss_min = val_loss  #その時のlossを記録する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55720b18-dcac-420f-a31b-49194d6045fa",
   "metadata": {},
   "source": [
    "## 訓練（ネットワークが通るか確認）  \n",
    "https://atmarkit.itmedia.co.jp/ait/articles/2006/12/news021.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2617a006-93d0-421c-aa50-7a870273142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(values1, values2, rng, label1, label2):\n",
    "    plt.plot(range(rng), values1, label=label1)\n",
    "    plt.plot(range(rng), values2, label=label2)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "be6637f1-bd47-4c9e-9a0b-5b9478dd7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataloader, criterion, optimizer,device):\n",
    "    net.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #print('入力:',inputs.shape , labels.shape,labels.dtype)\n",
    "\n",
    "        ##image = inputs[:,:3]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        #print('評価:',outputs.shape , labels.shape,labels.dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, ons_labels = torch.max(labels, 1)\n",
    "        total_correct += (predicted == ons_labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate(net, dataloader, criterion,device):\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, ons_labels = torch.max(labels, 1)\n",
    "            total_correct += (predicted == ons_labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_accuracy = total_correct / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, avg_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38cb4493-aa41-480b-9dfa-b8a8990ef21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train_and_validate(net, trainset, criterion, optimizer,scheduler, epochs,device):\n",
    "    best_accuracy = 0.0\n",
    "    trainloader, validloader = trainset\n",
    "    curEarlyStopping = EarlyStopping(patience=10, verbose=True,path=new_dir_path_recursive+'checkpoint_model.pth')\n",
    "\n",
    "    history = {}\n",
    "    history['train_loss_values'] = []\n",
    "    history['train_accuracy_values'] = []\n",
    "    history['valid_loss_values'] = []\n",
    "    history['valid_accuracy_values'] = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        current_time = datetime.now()\n",
    "        formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f'epoch: {epoch:3} <{formatted_time}>')\n",
    "\n",
    "        t_loss, t_accu = train(net, trainloader, criterion, optimizer,device)\n",
    "        v_loss, v_accu = validate(net, validloader, criterion,device)\n",
    "\n",
    "        print(f'train_loss: {t_loss:.6f}, train_accuracy: {t_accu:3.4%},',\n",
    "              f'valid_loss: {v_loss:.6f}, valid_accuracy: {v_accu:3.4%}')\n",
    "\n",
    "        history['train_loss_values'].append(t_loss)\n",
    "        history['train_accuracy_values'].append(t_accu)\n",
    "        history['valid_loss_values'].append(v_loss)\n",
    "        history['valid_accuracy_values'].append(v_accu)\n",
    "        pd.DataFrame(history).to_csv(new_dir_path_recursive+'mynet_spec.csv')\n",
    "        if best_accuracy < v_accu:\n",
    "            best_accuracy = v_accu\n",
    "            model_scripted = torch.jit.script(net)\n",
    "            model_scripted.save(new_dir_path_recursive+f'model_scripted_{epoch}.smodel.pth')\n",
    "        # 学習率の動的変更\n",
    "        scheduler.step(v_loss)\n",
    "        #★毎エポックearlystoppingの判定をさせる★\n",
    "        curEarlyStopping( v_loss , net) #callメソッド呼び出し\n",
    "        if curEarlyStopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "            print(\"Early Stopping!\")\n",
    "            return history\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21bf239b-71a8-49e0-8aa4-d00309da60c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghost\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終段 Linear(in_features=2051, out_features=7, bias=True)\n",
      "epoch:   1 <2024-02-17 11:25:10>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x2048 and 2051x7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m     20\u001b[0m trainset \u001b[38;5;241m=\u001b[39m [train_loader,test_loader]\n\u001b[1;32m---> 22\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdo_train_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 17\u001b[0m, in \u001b[0;36mdo_train_and_validate\u001b[1;34m(net, trainset, criterion, optimizer, scheduler, epochs, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m formatted_time \u001b[38;5;241m=\u001b[39m current_time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformatted_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m t_loss, t_accu \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m v_loss, v_accu \u001b[38;5;241m=\u001b[39m validate(net, validloader, criterion,device)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_accu\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3.4%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, valid_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_accu\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3.4%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m inputs[:,:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#print('評価:',outputs.shape , labels.shape,labels.dtype)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torchvision\\models\\inception.py:166\u001b[0m, in \u001b[0;36mInception3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InceptionOutputs:\n\u001b[0;32m    165\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_input(x)\n\u001b[1;32m--> 166\u001b[0m     x, aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     aux_defined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_logits\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torchvision\\models\\inception.py:153\u001b[0m, in \u001b[0;36mInception3._forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    151\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# N x 2048\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# N x 1000 (num_classes)\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, aux\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x2048 and 2051x7)"
     ]
    }
   ],
   "source": [
    "## 学習開始\n",
    "\n",
    "train_dataset = ImgValueDataset( train_df ,classcol=labels_cols , fncol='filepath',extendcol = extend_cols , transform=transform_train)\n",
    "test_dataset = ImgValueDataset( test_df ,classcol=labels_cols , fncol='filepath' ,extendcol = extend_cols ,transform=transform_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "net = createMyNet().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "## 5エポック改善がみなれないと\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, verbose=True)\n",
    "\n",
    "EPOCHS = 300\n",
    "trainset = [train_loader,test_loader]\n",
    "\n",
    "history = do_train_and_validate(net, trainset, criterion, optimizer, scheduler,EPOCHS,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ebd9a-bbfe-44f7-a437-5119d9ed677a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
