{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c96b46d-5437-422b-a0e7-88025aae5809",
   "metadata": {},
   "source": [
    "# 練習環境  \n",
    "- 限定されたサンプルを扱うなので、全サンプルから使えるサンプルだけのdatasetを作成する\n",
    "- TrainのDatasetの各ＲＧＢチャンネルの平均と分散をとっておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53291524-78c5-4b9e-9a4d-a764b46193d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Meiryo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "326f456c-364f-4f0e-ab68-793b963c6102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fn = r'./backup/dataset_cur_train.csv'\n",
    "valid_fn = r'./backup/dataset_cur_valid.csv'\n",
    "os.path.exists(train_fn) , os.path.exists(valid_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e056dce-cf14-430c-ba24-e88eed328a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_cur_train.csv (3370, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_fn,index_col=0)\n",
    "ex = df['filepath'].map(os.path.exists)\n",
    "save_fn = os.path.basename(train_fn)\n",
    "df = df.loc[ex]\n",
    "df.to_csv(save_fn)\n",
    "print(save_fn , df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b03406a-f52f-4df1-aafd-b4c297a95a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_cur_valid.csv (369, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(valid_fn,index_col=0)\n",
    "ex = df['filepath'].map(os.path.exists)\n",
    "save_fn = os.path.basename(valid_fn)\n",
    "df = df.loc[ex]\n",
    "df.to_csv(save_fn)\n",
    "print(save_fn , df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9f358-8e02-403e-a215-6a9cc478cc26",
   "metadata": {},
   "source": [
    "### 画素の分布を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d77421-273a-4ebd-8a69-13d92d746504",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = r'dataset_cur_train.csv'\n",
    "valid_fn = r'dataset_cur_valid.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52e50be4-9bf6-40d7-b376-d8d13a1e1963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_posiotn</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_diff  remain_ends  last_stone_is_red  red_posiotn  \\\n",
       "3      -2.0            5               True         -2.0   \n",
       "0       2.0            8               True          0.0   \n",
       "8      -3.0            0              False          4.0   \n",
       "\n",
       "                                           filepath  \n",
       "3  ./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png  \n",
       "0  ./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png  \n",
       "8  ./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(train_fn,index_col=0)\n",
    "display(df.shape , df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "841a9ebf-5c55-4f0e-aef5-f72017c82a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([7.86710501, 7.86710501, 7.86710501])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'std'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([44.877377, 44.877377, 44.877377], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ほどんど白なのでＲＧＢ全部1に近いはずなのに...この計算は没。\n"
     ]
    }
   ],
   "source": [
    "srcimages = []\n",
    "for path in df['filepath'].values:\n",
    "    image = Image.open(path)\n",
    "    image_data = np.array(image)\n",
    "    normalized_image = image_data.astype(np.float32)\n",
    "    srcimages.append(normalized_image)\n",
    "mean = np.mean(srcimages, axis=(0, 1, 2))\n",
    "std = np.std(srcimages, axis=(0, 1, 2))\n",
    "display('mean',mean.astype(float) , 'std',std )\n",
    "print(\"ほどんど白なのでＲＧＢ全部1に近いはずなのに...この計算は没。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eaf2eab9-5076-460b-8322-17930793332e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([247.74107, 246.41354, 248.74603], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([247.73212, 246.44182, 248.80464], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([132.56071, 132.56071, 132.56071], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean1 = np.mean(srcimages[0:100], axis=(0, 1, 2))\n",
    "mean2 = np.mean(srcimages[100:200], axis=(0, 1, 2))\n",
    "mean3 = np.mean(srcimages[0:200], axis=(0, 1, 2))\n",
    "display(mean1 , mean2 , mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38e6443-59c4-4f75-9368-29bdafc57933",
   "metadata": {},
   "source": [
    "#　計算を改良その１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e2aeb6c-27f6-4de2-88ec-e56abe796377",
   "metadata": {},
   "outputs": [],
   "source": [
    "srcimages = []\n",
    "for path in df['filepath'].values:\n",
    "    image = Image.open(path)\n",
    "    image_data = np.array(image)\n",
    "    normalized_image = image_data.astype(np.float32)\n",
    "    srcimages.append(normalized_image)\n",
    "pictar = np.array( srcimages ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3786c406-a6a4-4099-99e4-65c19f031aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370, 540, 300, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3370"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['R:G:B', 41.334015]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[240.97672, 238.83188, 246.84894]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[41.334015, 43.989445, 41.610004]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pictar.shape,len(pictar[:,:,:,0]))\n",
    "\n",
    "display(['R:G:B',pictar[:,:,:,0].std()] )\n",
    "display([ pictar[:,:,:,0].mean() , pictar[:,:,:,1].mean() , pictar[:,:,:,2].mean() ])\n",
    "display([ pictar[:,:,:,0].std() , pictar[:,:,:,1].std() ,pictar[:,:,:,2].std() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710e25c-d19c-42f2-8162-8cbaee65e037",
   "metadata": {},
   "source": [
    "#　計算を改良その2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d4df5c1-29ce-44fa-95ea-d722d7e0e819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370, 540, 300, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3370"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['R:G:B', 0.16211227]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.94500345, 0.936601, 0.96805465]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.16211227, 0.17250435, 0.16316637]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "srcimages = []\n",
    "for path in df['filepath'].values:\n",
    "    image = Image.open(path)\n",
    "    image_data = np.array(image)\n",
    "    normalized_image = image_data.astype(np.float32) / 255\n",
    "    srcimages.append(normalized_image)\n",
    "pictar = np.array( srcimages ) \n",
    "display(pictar.shape,len(pictar[:,:,:,0]))\n",
    "\n",
    "display(['R:G:B',pictar[:,:,:,0].std()] )\n",
    "display([ pictar[:,:,:,0].mean() , pictar[:,:,:,1].mean() , pictar[:,:,:,2].mean() ])\n",
    "display([ pictar[:,:,:,0].std() , pictar[:,:,:,1].std() ,pictar[:,:,:,2].std() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc5e09-48d9-4425-99f4-f15c9593f931",
   "metadata": {},
   "source": [
    "その２の値は妥当っぽい。ほぼ白だしなので１に近く、分散も低い  \n",
    "しかし本番では、正方形にするため、余白を作ってさらにセンタークリップを行うので条件は変わる。\n",
    "本番の変換を模索してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "23600714-4e12-4a2f-afff-7739f0dd23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f1d214fd-cf16-44d7-ba69-0ddd3093d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 余白なしで計算をしてみる\n",
    "target_size = 224\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Pad(( 240 // 2, 0), fill=255, padding_mode='constant'),  # 左右に余白を追加\n",
    "    #transforms.Resize(target_size),\n",
    "    #transforms.CenterCrop(target_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f9a6bb8a-579a-4d18-862e-40057504e1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3370, 3, 540, 300])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.9453915357589722, 0.9369375109672546, 0.9683912396430969]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.16209395229816437, 0.1724938601255417, 0.16317903995513916]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "srcimages = []\n",
    "for path in df['filepath'].values:\n",
    "    image = Image.open(path)\n",
    "    q = transform(image)\n",
    "    q = q.unsqueeze(dim=0)\n",
    "    srcimages.append(q)\n",
    "tensor1 = torch.cat(srcimages)\n",
    "display(tensor1.shape)\n",
    "display(\n",
    "    [tensor1[:,0,:,:].mean().item() ,tensor1[:,1,:,:].mean().item(),tensor1[:,2,:,:].mean().item()],\n",
    "    [tensor1[:,0,:,:].std().item() ,tensor1[:,1,:,:].std().item(),tensor1[:,2,:,:].std().item()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec952b80-5d44-48c5-96ee-686ffa50884b",
   "metadata": {},
   "source": [
    "numpyでの計算に一致したので、本番の変換をかけて算出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9145135a-6aeb-435a-968c-ecd0dadda514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3370, 3, 224, 224])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.525406002998352, 0.5207120180130005, 0.5381810665130615]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.47722673416137695, 0.4751463830471039, 0.48789089918136597]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 余白あり\n",
    "target_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "srcimages = []\n",
    "for path in df['filepath'].values:\n",
    "    image = Image.open(path)\n",
    "    q = transform(image)\n",
    "    q = q.unsqueeze(dim=0)\n",
    "    srcimages.append(q)\n",
    "tensor1 = torch.cat(srcimages)\n",
    "display(tensor1.shape)\n",
    "display(\n",
    "    [tensor1[:,0,:,:].mean().item() ,tensor1[:,1,:,:].mean().item(),tensor1[:,2,:,:].mean().item()],\n",
    "    [tensor1[:,0,:,:].std().item() ,tensor1[:,1,:,:].std().item(),tensor1[:,2,:,:].std().item()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a18d7-d8e7-4fb1-80fc-f7f5bdce7c7b",
   "metadata": {},
   "source": [
    "適当そうなので、自前の学習の時はこれを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d50e0c-3daa-4f19-860b-37208c44c4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
