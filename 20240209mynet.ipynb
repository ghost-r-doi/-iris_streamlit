{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4b3af0-8796-4f91-a3b8-a189ed4b5b47",
   "metadata": {},
   "source": [
    "# 自前のネットワークを組んで学習させてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7703dc5b-ee9d-4aaa-add2-f96d5029ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['font.family'] = 'Meiryo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41647b1b-afa7-4fd6-ae50-20a1694f1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = r'./dataset_cur_train.csv'\n",
    "valid_fn = r'./dataset_cur_valid.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5294d05-3e0d-461d-83fc-16ebda6d1449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "red_diff             float16\n",
       "remain_ends          float16\n",
       "last_stone_is_red    float16\n",
       "red_postion          float16\n",
       "filepath              object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_diff  remain_ends  last_stone_is_red  red_postion  \\\n",
       "3      -2.0          5.0                1.0         -2.0   \n",
       "0       2.0          8.0                1.0          0.0   \n",
       "8      -3.0          0.0                0.0          4.0   \n",
       "\n",
       "                                           filepath  \n",
       "3  ./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png  \n",
       "0  ./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png  \n",
       "8  ./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_fn,index_col=0)\n",
    "df_train['red_diff'] = df_train['red_diff'].astype(np.float16)\n",
    "df_train['remain_ends'] = df_train['remain_ends'].astype(np.float16)\n",
    "df_train['last_stone_is_red'] = df_train['last_stone_is_red'].astype(np.float16)\n",
    "df_train['red_postion'] = df_train['red_postion'].astype(np.float16)\n",
    "display(df_train.dtypes)\n",
    "display(df_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416d239-816d-4246-98c9-68aa35baafb0",
   "metadata": {},
   "source": [
    "## red_diff が目的、fn,remain_ends,last_stone_is_red,red_postion が説明変数\n",
    "説明変数を標準化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba7ce319-2e82-424f-94ff-2a6171635c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3816 ,  0.9927 , -0.846  ],\n",
       "       [ 1.538  ,  0.9927 ,  0.02896],\n",
       "       [-1.546  , -1.007  ,  1.78   ]], dtype=float16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['remain_ends', 'last_stone_is_red', 'red_postion']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-3.67840957e-05,  2.85724221e-04,  5.77388956e-05])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.00020842, 0.99994928, 1.00024519])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.381592</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>-0.846191</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.538086</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.545898</td>\n",
       "      <td>-1.006836</td>\n",
       "      <td>1.780273</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767090</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.466797</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme68end3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.152344</td>\n",
       "      <td>-1.006836</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>./dataset_o\\WWCC2023_ResultsBook\\geme158end2.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_diff  remain_ends  last_stone_is_red  red_postion  \\\n",
       "3      -2.0     0.381592           0.992676    -0.846191   \n",
       "0       2.0     1.538086           0.992676     0.028961   \n",
       "8      -3.0    -1.545898          -1.006836     1.780273   \n",
       "2       0.0     0.767090           0.992676     0.466797   \n",
       "1      -1.0     1.152344          -1.006836     0.028961   \n",
       "\n",
       "                                           filepath  \n",
       "3  ./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png  \n",
       "0  ./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png  \n",
       "8  ./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png  \n",
       "2   ./dataset_o\\WMCC2023_ResultsBook\\geme68end3.png  \n",
       "1  ./dataset_o\\WWCC2023_ResultsBook\\geme158end2.png  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化\n",
    "stdsc = StandardScaler()\n",
    "##学習時の標準化したパラメータは、評価、本番時におなじ重みで標準化する処理が必要\n",
    "x_train_df = df_train.copy().drop(['filepath','red_diff'],axis=1)\n",
    "x_train_std = stdsc.fit_transform(x_train_df)\n",
    "display( x_train_std[:3] )\n",
    "## DataFrameの値を入れ替え\n",
    "qcl = df_train.columns.to_list()\n",
    "qcl.remove('filepath')\n",
    "qcl.remove('red_diff')\n",
    "print(qcl)\n",
    "df_train[qcl] = x_train_std\n",
    "pickle.dump(stdsc, open(\"stdsc_02240209.pkl\", \"wb\"))\n",
    "display(stdsc.n_features_in_, stdsc.mean_ , stdsc.var_) \n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f4a74-d1e7-4304-a0f7-933485b4a9ba",
   "metadata": {},
   "source": [
    "### 20240209_samplescreeningで画像の平均 分散は計算ずみ\n",
    "平均:[0.525406002998352, 0.5207120180130005, 0.5381810665130615]  \r",
    "分散:\n",
    "[0.47722673416137695, 0.4751463830471039, 0.48789089918136597  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc251581-3052-406f-94bf-c781ea7943a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d98501e-1d3d-4b23-bb83-646cf5a3f981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 540]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 画像変換の定義\n",
    "w,h = Image.open(df_train['filepath'].values[0]).size\n",
    "## 正方形にするための差分\n",
    "pad = (h-w)/2\n",
    "display([w,h],pad)\n",
    "target_size = 224\n",
    "## train用\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5254, 0.521, 0.538], std=[0.477, 0.475, 0.487])\n",
    "])\n",
    "# valid/test用\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5254, 0.521, 0.538], std=[0.477, 0.475, 0.487])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22f5154d-84a6-42eb-b638-dbab73d94516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f773c-6504-40e9-a103-bd8b100ab1a2",
   "metadata": {},
   "source": [
    "# 自前のデータセット定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f04521e7-c7bd-4a5d-9a0c-71a00502dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgValueDataset(Dataset):\n",
    "    def __init__(self, df, classcol , fncol , transform):\n",
    "        \n",
    "        ##self.label_list  = df[classcol].to_list()\n",
    "        self.label_list  = pd.get_dummies(df[classcol]).values\n",
    "        self.img_pathlist  = df[fncol].to_list()\n",
    "        cols = df.columns.to_list()\n",
    "        cols.remove(fncol)\n",
    "        cols.remove(classcol)\n",
    "        self.x_values = df[cols].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len( self.img_pathlist )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 画像をPILとして読み込む\n",
    "        #print(index)\n",
    "        image = Image.open(self.img_pathlist[index])\n",
    "        \n",
    "        label = self.label_list[index]\n",
    "                             \n",
    "        if self.transform is not None:\n",
    "            ##print('use transform')\n",
    "            image = self.transform(image)\n",
    "        return image, label \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c1a795a1-a4b0-4f93-bb8d-9544cce15f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_train, test_size=0.2, stratify=df['red_diff'])\n",
    "train_dataset = ImgValueDataset( train_df ,classcol='red_diff' , fncol='filepath',transform=transform_train)\n",
    "test_dataset = ImgValueDataset( test_df ,classcol='red_diff' , fncol='filepath' ,transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4a9aa0e0-f19c-4983-846a-4fb6955f5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b80edabd-3b50-49e8-aec9-88cb63cfa1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 224, 224]),\n",
       " tensor([[False, False, False, False, False, False,  True, False, False, False,\n",
       "          False],\n",
       "         [False, False, False,  True, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False,  True, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False,  True, False, False, False,\n",
       "          False]]))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d0d21d0a-ca15-4f11-81b1-6603377007d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0., -1., -4., -2.,  2., -3.,  4.,  3., -5.,  5.],\n",
       "       dtype=float16),\n",
       " 11)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = train_df['red_diff'].unique()\n",
    "class_list , len(class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcadbf7-2c6d-42ae-bd54-f8cb49125471",
   "metadata": {},
   "source": [
    "試しに汎用モデルを読む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3ebf17f1-7549-467e-b40a-6e61dc28cba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://zl-hlb.ngk.co.jp:8080'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"http_proxy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3b46e373-39ed-4282-a411-ebed3c636b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' あきらめ\\nfrom torchvision import models \\nimport pprint\\nfrom torchvision.models import MobileNetV2\\nos.environ[\"http_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\\nos.environ[\"https_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\\nModel = models.mobilenet_v2(pretrained=True)\\nModel\\n'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" あきらめ\n",
    "from torchvision import models \n",
    "import pprint\n",
    "from torchvision.models import MobileNetV2\n",
    "os.environ[\"http_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\n",
    "os.environ[\"https_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\n",
    "Model = models.mobilenet_v2(pretrained=True)\n",
    "Model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f0cda-b0ce-4e75-a54d-7cbc9ac14da9",
   "metadata": {},
   "source": [
    "# ネットを組む  \n",
    "https://qiita.com/poorko/items/c151ff4a827f114fe954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f1b9b5f2-4064-4e3d-861a-bc23310ac89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "27da4588-b7ef-42ff-a8c2-0951db5e44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNモデルの定義\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(24)\n",
    "        \n",
    "        self.fc1 = nn.Linear(24*106*106, 10240)\n",
    "        self.fc2 = nn.Linear(10240, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "      \n",
    "        output = F.relu(self.bn1(self.conv1(input)))      \n",
    "        output = F.relu(self.bn2(self.conv2(output)))     \n",
    "        output = self.pool(output)                        \n",
    "        output = F.relu(self.bn4(self.conv4(output)))     \n",
    "        output = F.relu(self.bn5(self.conv5(output)))   \n",
    "        ###print(output.shape)\n",
    "        output = output.view(-1, 24*106*106)\n",
    "        output = F.relu(self.fc1(output))  # fc1->relu\n",
    "        output = F.relu(self.fc2(output))  # fc2->relu\n",
    "        output = self.fc3(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "44185bb6-5b7a-41fc-bb5b-37e21e21a5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=269664, out_features=10240, bias=True)\n",
      "  (fc2): Linear(in_features=10240, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = SimpleCNN(11)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0cdb6-eb60-4e7f-affa-9543292a91f7",
   "metadata": {},
   "source": [
    "## 損失関数とオプティマイザ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "176fad73-44a8-4be0-adec-1a7b5b9f13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a382c74a-027d-41b9-a696-ae720728ab62",
   "metadata": {},
   "source": [
    "## 訓練（ネットワークが通るか確認）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f8ef34ff-271c-40b8-86c8-584babfeca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def saveModel():\n",
    "    path = \"./20240209.Model.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ff060-9a66-475e-b945-232d7afd9700",
   "metadata": {},
   "source": [
    "## 学習可能か確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b04518-7ea4-418d-8034-ce04bd42988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cpu device\n",
      "min_batch: start:0\n",
      "min_batch: start:1\n",
      "min_batch: start:2\n",
      "min_batch: start:3\n",
      "min_batch: start:4\n",
      "min_batch: start:5\n",
      "min_batch: start:6\n",
      "min_batch: start:7\n",
      "min_batch: start:8\n",
      "min_batch: start:9\n",
      "min_batch: start:10\n",
      "min_batch: start:11\n",
      "min_batch: start:12\n",
      "min_batch: start:13\n",
      "min_batch: start:14\n",
      "min_batch: start:15\n",
      "min_batch: start:16\n",
      "min_batch: start:17\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "est_accuracy = 0.0\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,drop_last = True)\n",
    "\n",
    "# Define your execution device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The model will be running on\", device, \"device\")\n",
    "net.to(device)\n",
    "min_loss = 999999999\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    train_loss = 0.0;val_loss = 0.0\n",
    "    train_batches = 0;val_batches = 0\n",
    "\n",
    "    net.train()  # 訓練モード\n",
    "    for index_minbatch , (inputs, labels) in enumerate(train_loader, 0):\n",
    "        print(f'min_batch: start:{index_minbatch}')\n",
    "        inputs ,labels_float  = inputs.to(device) , labels.float().to(device)\n",
    "        # 勾配のリセット\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)    # 順方向計算\n",
    "        loss = criterion(outputs, labels_float)   # 損失の計算\n",
    "        loss.backward()                     # 逆方向計算(勾配計算)\n",
    "        optimizer.step()                    # パラメータの更新  \n",
    "        \n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d1b5fa45-0b80-406f-af62-7ea7c0722a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.float64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.dtype , labels_float.dtype ,labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "52ac6cb1-332f-4de3-867e-e55994e545bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 11]), torch.Size([16]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape , labels_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0c903c83-0e72-4f73-9737-b73fd91c2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5408b208-6a5f-40cb-a973-0d6d4f0af6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., -1.,  0.,  2., -1., -1., -1., -3.,  1.,  2.,  1.,  0.,  1.,  1.,\n",
       "         1., -2.])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08465bd-8486-4ca3-ab7f-fdc346c893b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
