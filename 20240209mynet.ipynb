{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4b3af0-8796-4f91-a3b8-a189ed4b5b47",
   "metadata": {},
   "source": [
    "# 自前のネットワークを組んで学習させてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7703dc5b-ee9d-4aaa-add2-f96d5029ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['font.family'] = 'Meiryo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41647b1b-afa7-4fd6-ae50-20a1694f1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = r'./dataset_cur_train.csv'\n",
    "valid_fn = r'./dataset_cur_valid.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5294d05-3e0d-461d-83fc-16ebda6d1449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "red_diff             float16\n",
       "remain_ends          float16\n",
       "last_stone_is_red    float16\n",
       "red_postion          float16\n",
       "filepath              object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_diff  remain_ends  last_stone_is_red  red_postion  \\\n",
       "3      -2.0          5.0                1.0         -2.0   \n",
       "0       2.0          8.0                1.0          0.0   \n",
       "8      -3.0          0.0                0.0          4.0   \n",
       "\n",
       "                                           filepath  \n",
       "3  ./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png  \n",
       "0  ./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png  \n",
       "8  ./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_fn,index_col=0)\n",
    "df_train['red_diff'] = df_train['red_diff'].astype(np.float16)\n",
    "df_train['remain_ends'] = df_train['remain_ends'].astype(np.float16)\n",
    "df_train['last_stone_is_red'] = df_train['last_stone_is_red'].astype(np.float16)\n",
    "df_train['red_postion'] = df_train['red_postion'].astype(np.float16)\n",
    "display(df_train.dtypes)\n",
    "display(df_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416d239-816d-4246-98c9-68aa35baafb0",
   "metadata": {},
   "source": [
    "## red_diff が目的、fn,remain_ends,last_stone_is_red,red_postion が説明変数\n",
    "説明変数を標準化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba7ce319-2e82-424f-94ff-2a6171635c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3816,  0.9927, -0.846 ],\n",
       "       [ 1.538 ,  0.9927,  0.0291],\n",
       "       [-1.546 , -1.007 ,  1.78  ]], dtype=float16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['remain_ends', 'last_stone_is_red', 'red_postion']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.00979228,  0.50356083, -0.06646884])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([6.73195159, 0.24998732, 5.21872729])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.381592</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>-0.846191</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.538086</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.545898</td>\n",
       "      <td>-1.006836</td>\n",
       "      <td>1.780273</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767090</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.466797</td>\n",
       "      <td>./dataset_o\\WMCC2023_ResultsBook\\geme68end3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.152344</td>\n",
       "      <td>-1.006836</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>./dataset_o\\WWCC2023_ResultsBook\\geme158end2.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_diff  remain_ends  last_stone_is_red  red_postion  \\\n",
       "3      -2.0     0.381592           0.992676    -0.846191   \n",
       "0       2.0     1.538086           0.992676     0.029099   \n",
       "8      -3.0    -1.545898          -1.006836     1.780273   \n",
       "2       0.0     0.767090           0.992676     0.466797   \n",
       "1      -1.0     1.152344          -1.006836     0.029099   \n",
       "\n",
       "                                           filepath  \n",
       "3  ./dataset_o\\WWCC2022_ResultsBook\\geme536end4.png  \n",
       "0  ./dataset_o\\WMCC2023_ResultsBook\\geme271end1.png  \n",
       "8  ./dataset_o\\WMCC2023_ResultsBook\\geme346end9.png  \n",
       "2   ./dataset_o\\WMCC2023_ResultsBook\\geme68end3.png  \n",
       "1  ./dataset_o\\WWCC2023_ResultsBook\\geme158end2.png  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化\n",
    "stdsc = StandardScaler()\n",
    "##学習時の標準化したパラメータは、評価、本番時におなじ重みで標準化する処理が必要\n",
    "x_train_df = df_train.copy().drop(['filepath','red_diff'],axis=1)\n",
    "x_train_std = stdsc.fit_transform(x_train_df)\n",
    "display( x_train_std[:3] )\n",
    "## DataFrameの値を入れ替え\n",
    "qcl = df_train.columns.to_list()\n",
    "qcl.remove('filepath')\n",
    "qcl.remove('red_diff')\n",
    "print(qcl)\n",
    "df_train[qcl] = x_train_std\n",
    "pickle.dump(stdsc, open(\"stdsc_02240209.pkl\", \"wb\"))\n",
    "display(stdsc.n_features_in_, stdsc.mean_ , stdsc.var_) \n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f4a74-d1e7-4304-a0f7-933485b4a9ba",
   "metadata": {},
   "source": [
    "### 20240209_samplescreeningで画像の平均 分散は計算ずみ\n",
    "平均:[0.525406002998352, 0.5207120180130005, 0.5381810665130615]  \r",
    "分散:\n",
    "[0.47722673416137695, 0.4751463830471039, 0.48789089918136597  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc251581-3052-406f-94bf-c781ea7943a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d98501e-1d3d-4b23-bb83-646cf5a3f981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 540]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 画像変換の定義\n",
    "w,h = Image.open(df_train['filepath'].values[0]).size\n",
    "## 正方形にするための差分\n",
    "pad = (h-w)/2\n",
    "display([w,h],pad)\n",
    "target_size = 224\n",
    "## train用\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5254, 0.521, 0.538], std=[0.477, 0.475, 0.487])\n",
    "])\n",
    "# valid/test用\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Pad(( 240 // 2, 0), fill=0, padding_mode='constant'),  # 左右に余白を追加\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5254, 0.521, 0.538], std=[0.477, 0.475, 0.487])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a965c7f0-479f-4f7a-b273-1de87dd9417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_diff</th>\n",
       "      <th>remain_ends</th>\n",
       "      <th>last_stone_is_red</th>\n",
       "      <th>red_postion</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.774414</td>\n",
       "      <td>-1.006836</td>\n",
       "      <td>0.904785</td>\n",
       "      <td>./dataset_o\\WWCC2022_ResultsBook\\geme374end7.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003773</td>\n",
       "      <td>-1.006836</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>./dataset_o\\WMCC2021_ResultsBook\\geme656end5.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_diff  remain_ends  last_stone_is_red  red_postion  \\\n",
       "6      -2.0    -0.774414          -1.006836     0.904785   \n",
       "4       0.0    -0.003773          -1.006836     0.029099   \n",
       "\n",
       "                                           filepath  \n",
       "6  ./dataset_o\\WWCC2022_ResultsBook\\geme374end7.png  \n",
       "4  ./dataset_o\\WMCC2021_ResultsBook\\geme656end5.png  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22f5154d-84a6-42eb-b638-dbab73d94516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f773c-6504-40e9-a103-bd8b100ab1a2",
   "metadata": {},
   "source": [
    "# 自前のデータセット定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f04521e7-c7bd-4a5d-9a0c-71a00502dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgValueDataset(Dataset):\n",
    "    def __init__(self, df, classcol , fncol , transform):\n",
    "        \n",
    "        ##self.label_list  = df[classcol].to_list()\n",
    "        self.label_list  = pd.get_dummies(df[classcol]).values\n",
    "        self.img_pathlist  = df[fncol].to_list()\n",
    "        cols = df.columns.to_list()\n",
    "        cols.remove(fncol)\n",
    "        cols.remove(classcol)\n",
    "        self.x_values = df[cols].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len( self.img_pathlist )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 画像をPILとして読み込む\n",
    "        #print(index)\n",
    "        image = Image.open(self.img_pathlist[index])\n",
    "        \n",
    "        label = self.label_list[index]\n",
    "                             \n",
    "        if self.transform is not None:\n",
    "            ##print('use transform')\n",
    "            image = self.transform(image)\n",
    "        return image, label \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1a795a1-a4b0-4f93-bb8d-9544cce15f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_train, test_size=0.2, stratify=df_train['red_diff'])\n",
    "train_dataset = ImgValueDataset( train_df ,classcol='red_diff' , fncol='filepath',transform=transform_train)\n",
    "test_dataset = ImgValueDataset( test_df ,classcol='red_diff' , fncol='filepath' ,transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a9aa0e0-f19c-4983-846a-4fb6955f5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b80edabd-3b50-49e8-aec9-88cb63cfa1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 224, 224]),\n",
       " tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False,  True, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,  True, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False,  True, False, False,\n",
       "          False]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0d21d0a-ca15-4f11-81b1-6603377007d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.,  2., -2.,  0.,  3., -4., -3., -5.,  4.,  5.],\n",
       "       dtype=float16),\n",
       " 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = train_df['red_diff'].unique()\n",
    "class_list , len(class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcadbf7-2c6d-42ae-bd54-f8cb49125471",
   "metadata": {},
   "source": [
    "試しに汎用モデルを読む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ebf17f1-7549-467e-b40a-6e61dc28cba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'http_proxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp_proxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'http_proxy'"
     ]
    }
   ],
   "source": [
    "os.environ[\"http_proxy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b46e373-39ed-4282-a411-ebed3c636b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' あきらめ\\nfrom torchvision import models \\nimport pprint\\nfrom torchvision.models import MobileNetV2\\nos.environ[\"http_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\\nos.environ[\"https_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\\nModel = models.mobilenet_v2(pretrained=True)\\nModel\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" あきらめ\n",
    "from torchvision import models \n",
    "import pprint\n",
    "from torchvision.models import MobileNetV2\n",
    "os.environ[\"http_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\n",
    "os.environ[\"https_proxy\"] = \"http://zl-hlb.ngk.co.jp:8080\"\n",
    "Model = models.mobilenet_v2(pretrained=True)\n",
    "Model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f0cda-b0ce-4e75-a54d-7cbc9ac14da9",
   "metadata": {},
   "source": [
    "# ネットを組む  \n",
    "https://qiita.com/poorko/items/c151ff4a827f114fe954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1b9b5f2-4064-4e3d-861a-bc23310ac89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27da4588-b7ef-42ff-a8c2-0951db5e44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNモデルの定義\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(24)\n",
    "        \n",
    "        self.fc1 = nn.Linear(24*106*106, 10240)\n",
    "        self.fc2 = nn.Linear(10240, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "      \n",
    "        output = F.relu(self.bn1(self.conv1(input)))      \n",
    "        output = F.relu(self.bn2(self.conv2(output)))     \n",
    "        output = self.pool(output)                        \n",
    "        output = F.relu(self.bn4(self.conv4(output)))     \n",
    "        output = F.relu(self.bn5(self.conv5(output)))   \n",
    "        ###print(output.shape)\n",
    "        output = output.view(-1, 24*106*106)\n",
    "        output = F.relu(self.fc1(output))  # fc1->relu\n",
    "        output = F.relu(self.fc2(output))  # fc2->relu\n",
    "        output = self.fc3(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44185bb6-5b7a-41fc-bb5b-37e21e21a5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=269664, out_features=10240, bias=True)\n",
      "  (fc2): Linear(in_features=10240, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = SimpleCNN(11)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0cdb6-eb60-4e7f-affa-9543292a91f7",
   "metadata": {},
   "source": [
    "## 損失関数とオプティマイザ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "176fad73-44a8-4be0-adec-1a7b5b9f13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a382c74a-027d-41b9-a696-ae720728ab62",
   "metadata": {},
   "source": [
    "## 訓練（ネットワークが通るか確認）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8ef34ff-271c-40b8-86c8-584babfeca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def saveModel():\n",
    "    path = \"./20240209.Model.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def testAccuracy(model,test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ff060-9a66-475e-b945-232d7afd9700",
   "metadata": {},
   "source": [
    "## 学習可能か確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6b04518-7ea4-418d-8034-ce04bd42988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n",
      "min_batch: start:0\n",
      "min_batch: start:1\n",
      "min_batch: start:2\n",
      "min_batch: start:3\n",
      "min_batch: start:4\n",
      "min_batch: start:5\n",
      "min_batch: start:6\n",
      "min_batch: start:7\n",
      "min_batch: start:8\n",
      "min_batch: start:9\n",
      "[1,    10] loss: 14.195\n",
      "min_batch: start:10\n",
      "min_batch: start:11\n",
      "min_batch: start:12\n",
      "min_batch: start:13\n",
      "min_batch: start:14\n",
      "min_batch: start:15\n",
      "min_batch: start:16\n",
      "min_batch: start:17\n",
      "min_batch: start:18\n",
      "min_batch: start:19\n",
      "[1,    20] loss: 2.615\n",
      "min_batch: start:20\n",
      "min_batch: start:21\n",
      "min_batch: start:22\n",
      "min_batch: start:23\n",
      "min_batch: start:24\n",
      "min_batch: start:25\n",
      "min_batch: start:26\n",
      "min_batch: start:27\n",
      "min_batch: start:28\n",
      "min_batch: start:29\n",
      "[1,    30] loss: 2.398\n",
      "min_batch: start:30\n",
      "min_batch: start:31\n",
      "min_batch: start:32\n",
      "min_batch: start:33\n",
      "min_batch: start:34\n",
      "min_batch: start:35\n",
      "min_batch: start:36\n",
      "min_batch: start:37\n",
      "min_batch: start:38\n",
      "min_batch: start:39\n",
      "[1,    40] loss: 2.389\n",
      "min_batch: start:40\n",
      "min_batch: start:41\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "503",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 503",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#########################################\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtestAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor epoch\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe test accuracy over the whole test set is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# we want to save the model if the accuracy is the best\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 13\u001b[0m, in \u001b[0;36mtestAccuracy\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m     10\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     14\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# run the model on the test set to predict labels\u001b[39;00m\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\MITC17834B\\AppData\\Local\\miniconda3\\envs\\dl_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 503"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "best_accuracy = 0.0\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,drop_last = True)\n",
    "test_loader = DataLoader(test_df, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Define your execution device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The model will be running on\", device, \"device\")\n",
    "net.to(device)\n",
    "min_loss = 999999999\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    train_loss = 0.0;val_loss = 0.0\n",
    "    train_batches = 0;val_batches = 0\n",
    "    running_loss = 0.0 \n",
    "    net.train()  # 訓練モード\n",
    "    for index_minbatch , (inputs, labels) in enumerate(train_loader, 0):\n",
    "        print(f'min_batch: start:{index_minbatch}')\n",
    "        inputs ,labels_float  = inputs.to(device) , labels.float().to(device)\n",
    "        # 勾配のリセット\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)    # 順方向計算\n",
    "        loss = criterion(outputs, labels_float)   # 損失の計算\n",
    "        loss.backward()                     # 逆方向計算(勾配計算)\n",
    "        optimizer.step()                    # パラメータの更新  \n",
    "\n",
    "        # 損失関数の変化を１0ミニバッチごとに表示\n",
    "        running_loss += loss.item()     # extract the loss value\n",
    "        if index_minbatch % 10 == 9:    \n",
    "            # print every 1000 (twice per epoch) \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, index_minbatch + 1, running_loss / 10))\n",
    "            # zero the loss\n",
    "            running_loss = 0.0\n",
    "            pass\n",
    "    #########################################\n",
    "    accuracy = testAccuracy(net,test_loader)\n",
    "    print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "    # we want to save the model if the accuracy is the best\n",
    "    if accuracy > best_accuracy:\n",
    "        saveModel()\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5fa45-0b80-406f-af62-7ea7c0722a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.dtype , labels_float.dtype ,labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac6cb1-332f-4de3-867e-e55994e545bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape , labels_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c903c83-0e72-4f73-9737-b73fd91c2942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408b208-6a5f-40cb-a973-0d6d4f0af6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08465bd-8486-4ca3-ab7f-fdc346c893b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
